{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spacetrackのテスト その4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大量の軌道要素ファイルをまとめて取り扱いやすくするテスト。\n",
    "\n",
    "軌道要素データは既に download_gp_date_json.py で download/YYYY/ 以下にダウンロード済みであるものとする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import cProfile\n",
    "import h5py\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "# データの出力先 (十分な空き容量のあるストレージを指定する)\n",
    "outputpath = '/work/'\n",
    "\n",
    "# 既にダウンロードしxzで圧縮されたデータを用いる (download_gp_date_json.py でダウンロード)\n",
    "allfiles = sorted(glob.glob('download/1980/*.json.xz'))\n",
    "print(len(allfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各columnの型\n",
    "# https://www.space-track.org/basicspacedata/modeldef/class/gp/format/html も参照のこと\n",
    "# decimal型のcolumnはfloat64として取り扱うことにする\n",
    "# 型として str を指定すると、元データが null のとき、\"None\" という文字列になってしまうので、object を指定する\n",
    "# 実際の元データでnullとなっているものがあるのは COUNTRY_CODE, DECAY_DATE, LAUNCH_DATE, OBJECT_ID, RCS_SIZE, SITE\n",
    "dtype = {'CCSDS_OMM_VERS': object,  'COMMENT': object,  'CREATION_DATE': 'datetime64[ns]',  'ORIGINATOR': object, \n",
    "       'OBJECT_NAME': object,  'OBJECT_ID': object,  'CENTER_NAME': object,  'REF_FRAME': object, \n",
    "       'TIME_SYSTEM': object,  'MEAN_ELEMENT_THEORY': object,  'EPOCH': 'datetime64[ns]',  'MEAN_MOTION': 'float64', \n",
    "       'ECCENTRICITY': 'float64',  'INCLINATION': 'float64',  'RA_OF_ASC_NODE': 'float64', \n",
    "       'ARG_OF_PERICENTER': 'float64',  'MEAN_ANOMALY': 'float64',  'EPHEMERIS_TYPE': 'int8', \n",
    "       'CLASSIFICATION_TYPE': object,  'NORAD_CAT_ID': 'uint32',  'ELEMENT_SET_NO': 'uint16', \n",
    "       'REV_AT_EPOCH': 'uint32',  'BSTAR': 'float64',  'MEAN_MOTION_DOT': 'float64',  'MEAN_MOTION_DDOT': 'float64', \n",
    "       'SEMIMAJOR_AXIS': 'float64',  'PERIOD': 'float64',  'APOAPSIS': 'float64',  'PERIAPSIS': 'float64',  'OBJECT_TYPE': object, \n",
    "       'RCS_SIZE': object,  'COUNTRY_CODE': object,  'LAUNCH_DATE': 'datetime64[ns]',  'SITE': object,  'DECAY_DATE': 'datetime64[ns]', \n",
    "       'FILE': 'uint64',  'GP_ID': 'uint32',  'TLE_LINE0': object,  'TLE_LINE1': object,  'TLE_LINE2': object}\n",
    "\n",
    "# 以下のcolumnは日時として解釈する (元データが空欄の場合は NaT になる)\n",
    "convert_dates = ['EPOCH', 'CREATION_DATE', 'LAUNCH_DATE', 'DECAY_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column名\n",
    "columns = list(dtype.keys())\n",
    "\n",
    "# DBに出力するcolumn\n",
    "#columns_out = ['CREATION_DATE', 'EPOCH', 'OBJECT_ID', 'MEAN_MOTION', 'ECCENTRICITY', 'INCLINATION', 'RA_OF_ASC_NODE',\n",
    "#    'ARG_OF_PERICENTER', 'MEAN_ANOMALY', 'NORAD_CAT_ID', 'REV_AT_EPOCH', 'BSTAR', 'SEMIMAJOR_AXIS',\n",
    "#    'PERIOD', 'APOAPSIS', 'PERIAPSIS', 'GP_ID', 'TLE_LINE0', 'TLE_LINE1', 'TLE_LINE2']\n",
    "\n",
    "# indexに用いるcolumn\n",
    "columns_index = ['CREATION_DATE', 'EPOCH', 'OBJECT_ID', 'MEAN_MOTION', 'ECCENTRICITY', 'INCLINATION', 'RA_OF_ASC_NODE',\n",
    "    'ARG_OF_PERICENTER', 'MEAN_ANOMALY', 'NORAD_CAT_ID', 'REV_AT_EPOCH', 'BSTAR', 'SEMIMAJOR_AXIS',\n",
    "    'PERIOD', 'APOAPSIS', 'PERIAPSIS', 'GP_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nullデータを含むテストデータ\n",
    "# int型のcolumnにnullを含めると、DataFrameの列がobjectになり、to_hdfがエラーとなるので、適当な値を入れておく\n",
    "# gp APIが返すデータには、int型のcolumnにnullが含まれた実績はない(?)\n",
    "json_null = '[{\"CCSDS_OMM_VERS\":null,\"COMMENT\":null,\"CREATION_DATE\":null,\"ORIGINATOR\":null,\"OBJECT_NAME\":null,\"OBJECT_ID\":null,\"CENTER_NAME\":null,\"REF_FRAME\":null,\"TIME_SYSTEM\":null,\"MEAN_ELEMENT_THEORY\":null,\"EPOCH\":null,\"MEAN_MOTION\":null,\"ECCENTRICITY\":null,\"INCLINATION\":null,\"RA_OF_ASC_NODE\":null,\"ARG_OF_PERICENTER\":null,\"MEAN_ANOMALY\":null,\"EPHEMERIS_TYPE\":\"0\",\"CLASSIFICATION_TYPE\":null,\"NORAD_CAT_ID\":\"0\",\"ELEMENT_SET_NO\":\"0\",\"REV_AT_EPOCH\":\"0\",\"BSTAR\":null,\"MEAN_MOTION_DOT\":null,\"MEAN_MOTION_DDOT\":null,\"SEMIMAJOR_AXIS\":null,\"PERIOD\":null,\"APOAPSIS\":null,\"PERIAPSIS\":null,\"OBJECT_TYPE\":null,\"RCS_SIZE\":null,\"COUNTRY_CODE\":null,\"LAUNCH_DATE\":null,\"SITE\":null,\"DECAY_DATE\":null,\"FILE\":\"0\",\"GP_ID\":\"4294967295\",\"TLE_LINE0\":null,\"TLE_LINE1\":null,\"TLE_LINE2\":null}]'\n",
    "df_null = pd.read_json(json_null, convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト保存先ファイル名を定義\n",
    "file_json = outputpath + 'test.json'\n",
    "file_json2 = outputpath + 'test2.json'\n",
    "file_pickle = outputpath + 'test.pickle'\n",
    "file_pickle2 = outputpath + 'test.pickle.gz'\n",
    "file_parquet = outputpath + 'test.parquet'\n",
    "file_parquet2 = outputpath + 'test2.parquet'\n",
    "file_hdf = outputpath + 'test.hdf5'\n",
    "file_hdf2 = outputpath + 'test2.hdf5'\n",
    "file_sqlite = outputpath + 'test.sqlite3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファイル1個を読む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download/1980/19800101.json.xz\n"
     ]
    }
   ],
   "source": [
    "print(allfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.4 ms ± 194 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# ファイル1個を読む速度 (型を自動判定)\n",
    "def readtest1(file):\n",
    "    df_tmp = pd.read_json(file, convert_dates = convert_dates, precise_float = True, orient = 'records')\n",
    "    return df_tmp\n",
    "\n",
    "%timeit -r 5 df = readtest1(allfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.5 ms ± 115 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# ファイル1個を読む速度 (型を指定)\n",
    "def readtest1(file):\n",
    "    df_tmp = pd.read_json(file, convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'records')\n",
    "    return df_tmp\n",
    "\n",
    "%timeit -r 5 df = readtest1(allfiles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame に大量のデータを追加する速度を比較\n",
    "ファイル1個ごとにappendしていくと遅いので、最小回数で作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以降で使うテスト用データ\n",
    "df_test = pd.read_json(allfiles[0], convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 ms ± 130 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "5.41 s ± 12 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# appendでつなげていく (O(n^2)なのでデータ数が増えると使い物にならない)\n",
    "def appendtest(df_test, n):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(0, n):\n",
    "        df = df.append(df_test[columns], ignore_index=True)\n",
    "    return df\n",
    "        \n",
    "%timeit -r 5 df = appendtest(df_test, 10)\n",
    "%timeit -r 5 df = appendtest(df_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.4 ms ± 13.3 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "256 ms ± 686 µs per loop (mean ± std. dev. of 5 runs, 1 loop each)\n",
      "3 s ± 179 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# 全てのデータを1回のconcatで連結する\n",
    "def concattest(df_test, n):\n",
    "    df_list = []\n",
    "    for i in range(0, n):\n",
    "        df_list.append(df_test[columns])\n",
    "    df = pd.concat(df_list)\n",
    "    return df\n",
    "\n",
    "%timeit -r 5 df = concattest(df_test, 10)\n",
    "%timeit -r 5 df = concattest(df_test, 100)\n",
    "%timeit -r 5 df = concattest(df_test, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.3 ms ± 1.01 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "756 ms ± 239 µs per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# 列ごとにlistを作ってから、DataFrameに変換する (listを値とするdictを作成している)\n",
    "# from_dict に時間がかかっている\n",
    "def listtest(df_test, n):\n",
    "    d = {column: [] for column in columns}\n",
    "    for i in range(0, n):\n",
    "        for column in columns:\n",
    "            d[column].extend(df_test[column].values.tolist())\n",
    "            #d[column] += df_test[column].values.tolist()\n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    #df =  pd.DataFrame(data = d, columns = columns)  # 少し遅い\n",
    "    return df\n",
    "\n",
    "%timeit -r 5 df = listtest(df_test, 10)\n",
    "%timeit -r 5 df = listtest(df_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1620729 function calls (1616839 primitive calls) in 5.739 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      396    0.001    0.000    0.004    0.000 <__array_function__ internals>:2(argsort)\n",
      "      396    0.000    0.000    0.003    0.000 <__array_function__ internals>:2(atleast_2d)\n",
      "      200    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(can_cast)\n",
      "     2574    0.003    0.000    1.264    0.000 <__array_function__ internals>:2(concatenate)\n",
      "      398    0.000    0.000    0.002    0.000 <__array_function__ internals>:2(min_scalar_type)\n",
      "      396    0.001    0.000    0.645    0.002 <__array_function__ internals>:2(vstack)\n",
      "    10134    0.008    0.000    0.012    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "        1    0.314    0.314    5.733    5.733 <ipython-input-12-9eea22fa9f20>:2(appendtest)\n",
      "        1    0.006    0.006    5.739    5.739 <string>:1(<module>)\n",
      "     5685    0.002    0.000    0.009    0.000 _asarray.py:16(asarray)\n",
      "      796    0.004    0.000    0.007    0.000 _asarray.py:223(require)\n",
      "      796    0.001    0.000    0.001    0.000 _asarray.py:300(<setcomp>)\n",
      "     1685    0.000    0.000    0.001    0.000 _asarray.py:88(asanyarray)\n",
      "     4168    0.003    0.000    0.006    0.000 _dtype.py:190(_datetime_metadata_str)\n",
      "    16009    0.009    0.000    0.033    0.000 _dtype.py:319(_name_includes_bit_suffix)\n",
      "    16009    0.027    0.000    0.078    0.000 _dtype.py:333(_name_get)\n",
      "    16009    0.004    0.000    0.004    0.000 _dtype.py:36(_kind_name)\n",
      "      792    0.002    0.000    0.007    0.000 _dtype.py:46(__str__)\n",
      "      504    0.001    0.000    0.001    0.000 _internal.py:830(npy_ctypes_check)\n",
      "      700    0.000    0.000    0.004    0.000 _methods.py:28(_amax)\n",
      "      100    0.000    0.000    0.001    0.000 _methods.py:36(_sum)\n",
      "     4081    0.002    0.000    0.012    0.000 _methods.py:44(_any)\n",
      "     2388    0.001    0.000    0.013    0.000 _methods.py:47(_all)\n",
      "     1188    0.001    0.000    0.003    0.000 _mixins.py:70(shape)\n",
      "     1188    0.001    0.000    0.004    0.000 _mixins.py:77(ndim)\n",
      "      200    0.000    0.000    0.000    0.000 _validators.py:208(validate_bool_kwarg)\n",
      "      602    0.000    0.000    0.001    0.000 abc.py:96(__instancecheck__)\n",
      "      896    0.004    0.000    0.053    0.000 algorithms.py:1327(wrapper)\n",
      "      897    0.002    0.000    0.046    0.000 algorithms.py:1370(_take_nd_object)\n",
      "     3885    0.022    0.000    0.069    0.000 algorithms.py:1487(_get_take_nd_function)\n",
      "      897    0.001    0.000    0.048    0.000 algorithms.py:1514(func2)\n",
      "     3885    0.029    0.000    1.300    0.000 algorithms.py:1616(take_nd)\n",
      "      100    0.001    0.000    0.015    0.000 api.py:109(_get_combined_index)\n",
      "       99    0.001    0.000    0.009    0.000 api.py:161(union_indexes)\n",
      "       99    0.000    0.000    0.000    0.000 api.py:233(_sanitize_and_check)\n",
      "       99    0.000    0.000    0.000    0.000 api.py:254(<setcomp>)\n",
      "       99    0.000    0.000    0.002    0.000 api.py:271(get_consensus_names)\n",
      "       99    0.001    0.000    0.001    0.000 api.py:289(<setcomp>)\n",
      "      100    0.000    0.000    0.015    0.000 api.py:65(get_objs_combined_axis)\n",
      "      100    0.000    0.000    0.000    0.000 api.py:91(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 api.py:95(_get_distinct_objs)\n",
      "      897    0.000    0.000    0.000    0.000 base.py:1175(name)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:1182(name)\n",
      "      100    0.001    0.000    0.001    0.000 base.py:1193(_validate_names)\n",
      "      298    0.000    0.000    0.000    0.000 base.py:1213(_get_names)\n",
      "      100    0.000    0.000    0.001    0.000 base.py:1216(_set_names)\n",
      "      100    0.000    0.000    0.002    0.000 base.py:1246(set_names)\n",
      "      199    0.000    0.000    0.000    0.000 base.py:1378(nlevels)\n",
      "      100    0.000    0.000    0.001    0.000 base.py:1685(is_boolean)\n",
      "      100    0.000    0.000    0.001    0.000 base.py:2000(inferred_type)\n",
      "    33723    0.015    0.000    0.066    0.000 base.py:256(is_dtype)\n",
      "  406/202    0.005    0.000    0.026    0.000 base.py:293(__new__)\n",
      "      100    0.001    0.000    0.022    0.000 base.py:2957(get_indexer)\n",
      "      100    0.000    0.000    0.003    0.000 base.py:3194(_convert_listlike_indexer)\n",
      "      100    0.000    0.000    0.002    0.000 base.py:3216(_convert_arr_indexer)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:3247(_convert_list_indexer)\n",
      "      100    0.001    0.000    0.016    0.000 base.py:3291(reindex)\n",
      "     1496    0.000    0.000    0.000    0.000 base.py:3870(_values)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:3896(_get_engine_target)\n",
      "    30929    0.016    0.000    0.023    0.000 base.py:413(find)\n",
      "      499    0.002    0.000    0.021    0.000 base.py:4196(equals)\n",
      "      502    0.001    0.000    0.001    0.000 base.py:463(_simple_new)\n",
      "      100    0.000    0.000    0.022    0.000 base.py:4700(get_indexer_for)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:4717(_maybe_promote)\n",
      "      300    0.001    0.000    0.002    0.000 base.py:498(_shallow_copy)\n",
      "      499    0.000    0.000    0.000    0.000 base.py:520(is_)\n",
      "      602    0.000    0.000    0.000    0.000 base.py:544(_reset_identity)\n",
      "      902    0.001    0.000    0.027    0.000 base.py:5559(ensure_index)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:5623(ensure_has_len)\n",
      "      100    0.001    0.000    0.003    0.000 base.py:5650(default_index)\n",
      "      606    0.000    0.000    0.001    0.000 base.py:5656(maybe_extract_name)\n",
      "     1500    0.001    0.000    0.001    0.000 base.py:567(__len__)\n",
      "      202    0.000    0.000    0.001    0.000 base.py:5672(_maybe_cast_with_dtype)\n",
      "      202    0.001    0.000    0.003    0.000 base.py:5726(_maybe_cast_data_without_dtype)\n",
      "      300    0.000    0.000    0.000    0.000 base.py:590(dtype)\n",
      "      100    0.000    0.000    0.001    0.000 base.py:701(take)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:723(_assert_take_fillable)\n",
      "      100    0.000    0.000    0.004    0.000 base.py:793(copy)\n",
      "      700    0.003    0.000    0.070    0.000 blocks.py:1238(take_nd)\n",
      "     2896    0.007    0.000    0.020    0.000 blocks.py:124(__init__)\n",
      "     2896    0.002    0.000    0.002    0.000 blocks.py:135(_check_ndim)\n",
      "     3564    0.006    0.000    0.021    0.000 blocks.py:176(_consolidate_key)\n",
      "      100    0.000    0.000    0.000    0.000 blocks.py:2012(fill_value)\n",
      "      599    0.001    0.000    0.007    0.000 blocks.py:2048(__init__)\n",
      "      796    0.000    0.000    0.000    0.000 blocks.py:2052(_can_hold_na)\n",
      "      599    0.001    0.000    0.001    0.000 blocks.py:2056(_maybe_coerce_values)\n",
      "      597    0.000    0.000    0.002    0.000 blocks.py:213(get_values)\n",
      "     1197    0.000    0.000    0.000    0.000 blocks.py:229(fill_value)\n",
      "    14132    0.002    0.000    0.002    0.000 blocks.py:233(mgr_locs)\n",
      "     2896    0.003    0.000    0.007    0.000 blocks.py:237(mgr_locs)\n",
      "      799    0.001    0.000    0.008    0.000 blocks.py:2374(__init__)\n",
      "     1194    0.002    0.000    0.006    0.000 blocks.py:2380(is_bool)\n",
      "      703    0.001    0.000    0.003    0.000 blocks.py:256(make_block_same_class)\n",
      "     2193    0.009    0.000    0.047    0.000 blocks.py:2655(get_block_type)\n",
      "     2193    0.007    0.000    0.079    0.000 blocks.py:2701(make_block)\n",
      "      693    0.001    0.000    0.001    0.000 blocks.py:2728(_extend_blocks)\n",
      "     1500    0.001    0.000    0.001    0.000 blocks.py:276(__len__)\n",
      "     3582    0.001    0.000    0.001    0.000 blocks.py:311(shape)\n",
      "    11513    0.002    0.000    0.002    0.000 blocks.py:315(dtype)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1570(construct_1d_object_array_from_listlike)\n",
      "     3185    0.020    0.000    0.053    0.000 cast.py:442(maybe_promote)\n",
      "     3185    0.003    0.000    0.011    0.000 cast.py:598(_ensure_dtype_type)\n",
      "     1194    0.001    0.000    0.003    0.000 common.py:1025(is_datetime_or_timedelta_dtype)\n",
      "     1194    0.001    0.000    0.006    0.000 common.py:1180(needs_i8_conversion)\n",
      "      897    0.001    0.000    0.002    0.000 common.py:1223(is_numeric_dtype)\n",
      "     1194    0.001    0.000    0.002    0.000 common.py:1265(is_string_like_dtype)\n",
      "     1194    0.000    0.000    0.000    0.000 common.py:1293(<lambda>)\n",
      "     2893    0.002    0.000    0.006    0.000 common.py:1296(is_float_dtype)\n",
      "     2780    0.003    0.000    0.011    0.000 common.py:1330(is_bool_dtype)\n",
      "    30929    0.019    0.000    0.048    0.000 common.py:1460(is_extension_array_dtype)\n",
      "      200    0.000    0.000    0.000    0.000 common.py:150(ensure_python_int)\n",
      "     4872    0.003    0.000    0.030    0.000 common.py:1541(_is_dtype)\n",
      "     9252    0.003    0.000    0.004    0.000 common.py:1565(_get_dtype)\n",
      "    11457    0.006    0.000    0.012    0.000 common.py:1600(_is_dtype_type)\n",
      "      606    0.000    0.000    0.000    0.000 common.py:1733(pandas_dtype)\n",
      "      100    0.000    0.000    0.000    0.000 common.py:176(not_none)\n",
      "     9550    0.002    0.000    0.002    0.000 common.py:178(classes)\n",
      "      300    0.000    0.000    0.000    0.000 common.py:180(<genexpr>)\n",
      "     9550    0.002    0.000    0.003    0.000 common.py:180(<lambda>)\n",
      "     1907    0.000    0.000    0.000    0.000 common.py:183(classes_and_not_datetimelike)\n",
      "     1907    0.001    0.000    0.001    0.000 common.py:188(<lambda>)\n",
      "      100    0.000    0.000    0.000    0.000 common.py:190(all_none)\n",
      "      200    0.000    0.000    0.000    0.000 common.py:194(<genexpr>)\n",
      "     5257    0.004    0.000    0.010    0.000 common.py:194(is_object_dtype)\n",
      "      198    0.000    0.000    0.000    0.000 common.py:197(any_not_none)\n",
      "      396    0.000    0.000    0.000    0.000 common.py:201(<genexpr>)\n",
      "      506    0.001    0.000    0.004    0.000 common.py:218(asarray_tuplesafe)\n",
      "     9140    0.013    0.000    0.023    0.000 common.py:224(is_sparse)\n",
      "      100    0.000    0.000    0.000    0.000 common.py:329(apply_if_callable)\n",
      "     6147    0.003    0.000    0.003    0.000 common.py:348(is_datetime64_dtype)\n",
      "    12321    0.006    0.000    0.030    0.000 common.py:381(is_datetime64tz_dtype)\n",
      "     5371    0.002    0.000    0.003    0.000 common.py:422(is_timedelta64_dtype)\n",
      "     5784    0.004    0.000    0.022    0.000 common.py:456(is_period_dtype)\n",
      "     4198    0.003    0.000    0.015    0.000 common.py:492(is_interval_dtype)\n",
      "    12038    0.007    0.000    0.034    0.000 common.py:530(is_categorical_dtype)\n",
      "     3678    0.004    0.000    0.032    0.000 common.py:566(is_string_dtype)\n",
      "     3678    0.002    0.000    0.024    0.000 common.py:595(condition)\n",
      "     1692    0.001    0.000    0.022    0.000 common.py:598(is_excluded_dtype)\n",
      "     6768    0.002    0.000    0.019    0.000 common.py:603(<genexpr>)\n",
      "      800    0.001    0.000    0.001    0.000 common.py:608(is_dtype_equal)\n",
      "      202    0.000    0.000    0.000    0.000 common.py:696(is_integer_dtype)\n",
      "      404    0.000    0.000    0.001    0.000 common.py:750(is_signed_integer_dtype)\n",
      "      404    0.000    0.000    0.001    0.000 common.py:806(is_unsigned_integer_dtype)\n",
      "      812    0.000    0.000    0.000    0.000 common.py:905(is_datetime64_any_dtype)\n",
      "      100    0.000    0.000    0.004    0.000 common.py:97(is_bool_indexer)\n",
      "     1782    0.011    0.000    0.835    0.000 concat.py:110(concat_compat)\n",
      "     3564    0.002    0.000    0.002    0.000 concat.py:128(is_nonempty)\n",
      "     1782    0.001    0.000    0.003    0.000 concat.py:139(<listcomp>)\n",
      "     3564    0.001    0.000    0.002    0.000 concat.py:144(<genexpr>)\n",
      "     1782    0.001    0.000    0.001    0.000 concat.py:147(<setcomp>)\n",
      "     5346    0.002    0.000    0.007    0.000 concat.py:148(<genexpr>)\n",
      "     3582    0.001    0.000    0.001    0.000 concat.py:174(__init__)\n",
      "     2985    0.012    0.000    0.022    0.000 concat.py:185(needs_filling)\n",
      "     2985    0.003    0.000    0.027    0.000 concat.py:194(dtype)\n",
      "     3579    0.014    0.000    0.706    0.000 concat.py:204(is_na)\n",
      "     2985    0.012    0.000    1.248    0.000 concat.py:233(get_reindexed_values)\n",
      "     1782    0.010    0.000    0.056    0.000 concat.py:29(get_dtype_kinds)\n",
      "      100    0.003    0.000    1.966    0.020 concat.py:295(__init__)\n",
      "     1500    0.008    0.000    2.159    0.001 concat.py:306(_concatenate_join_units)\n",
      "      100    0.254    0.003    3.272    0.033 concat.py:31(concatenate_block_managers)\n",
      "     1500    0.004    0.000    1.252    0.001 concat.py:316(<listcomp>)\n",
      "     4455    0.001    0.000    0.002    0.000 concat.py:332(<genexpr>)\n",
      "     1500    0.024    0.000    0.095    0.000 concat.py:351(_get_empty_dtype_and_na)\n",
      "      396    0.003    0.000    0.178    0.000 concat.py:364(concat_datetime)\n",
      "      100    0.000    0.000    0.001    0.000 concat.py:379(<listcomp>)\n",
      "      396    0.001    0.000    0.104    0.000 concat.py:382(<listcomp>)\n",
      "      396    0.001    0.000    0.001    0.000 concat.py:383(<setcomp>)\n",
      "      396    0.002    0.000    0.005    0.000 concat.py:392(<listcomp>)\n",
      "      792    0.004    0.000    0.103    0.000 concat.py:403(_wrap_datetimelike)\n",
      "      100    0.004    0.000    3.283    0.033 concat.py:456(get_result)\n",
      "     1797    0.005    0.000    0.727    0.000 concat.py:465(_is_uniform_join_units)\n",
      "     5376    0.002    0.000    0.002    0.000 concat.py:476(<genexpr>)\n",
      "      100    0.000    0.000    0.023    0.000 concat.py:48(<listcomp>)\n",
      "     5376    0.009    0.000    0.715    0.000 concat.py:480(<genexpr>)\n",
      "     3891    0.001    0.000    0.001    0.000 concat.py:483(<genexpr>)\n",
      "     1500    0.001    0.000    0.005    0.000 concat.py:490(_is_uniform_reindex)\n",
      "     3000    0.002    0.000    0.003    0.000 concat.py:493(<genexpr>)\n",
      "      100    0.000    0.000    0.000    0.000 concat.py:511(_get_result_dim)\n",
      "      100    0.000    0.000    0.021    0.000 concat.py:517(_get_new_axes)\n",
      "      100    0.000    0.000    0.020    0.000 concat.py:519(<listcomp>)\n",
      "      100    0.000    0.000    0.016    0.000 concat.py:524(_get_comb_axis)\n",
      "     1900    0.010    0.000    0.015    0.000 concat.py:525(_combine_concat_plans)\n",
      "      100    0.001    0.000    0.004    0.000 concat.py:534(_get_concat_axis)\n",
      "     3762    0.001    0.000    0.002    0.000 concat.py:550(_next_or_none)\n",
      "      100    0.000    0.000    0.000    0.000 concat.py:567(<listcomp>)\n",
      "      299    0.000    0.000    0.000    0.000 concat.py:570(<genexpr>)\n",
      "      297    0.000    0.000    0.000    0.000 concat.py:66(<listcomp>)\n",
      "      100    0.001    0.000    5.250    0.052 concat.py:70(concat)\n",
      "      199    0.012    0.000    0.023    0.000 concat.py:87(_get_mgr_concatenation_plan)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:237(init_dict)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:274(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:277(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:280(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:329(_homogenize)\n",
      "     5469    0.002    0.000    0.010    0.000 construction.py:339(extract_array)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:360(extract_index)\n",
      "      792    0.004    0.000    0.098    0.000 construction.py:57(array)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:60(arrays_to_mgr)\n",
      "      792    0.000    0.000    0.000    0.000 datetimelike.py:1729(validate_inferred_freq)\n",
      "      792    0.001    0.000    0.001    0.000 datetimelike.py:1764(maybe_infer_freq)\n",
      "     1188    0.001    0.000    0.002    0.000 datetimelike.py:464(_ndarray)\n",
      "     1980    0.001    0.000    0.002    0.000 datetimelike.py:491(asi8)\n",
      "      396    0.002    0.000    0.063    0.000 datetimelike.py:671(_concat_same_type)\n",
      "      396    0.002    0.000    0.009    0.000 datetimelike.py:675(<setcomp>)\n",
      "      396    0.000    0.000    0.001    0.000 datetimelike.py:682(<listcomp>)\n",
      "      792    0.007    0.000    0.068    0.000 datetimes.py:1871(sequence_to_dt64ns)\n",
      "      792    0.002    0.000    0.014    0.000 datetimes.py:2085(maybe_convert_dtype)\n",
      "      792    0.000    0.000    0.000    0.000 datetimes.py:2178(_validate_dt64_dtype)\n",
      "     1584    0.000    0.000    0.000    0.000 datetimes.py:2220(validate_tz_from_dtype)\n",
      "     1188    0.002    0.000    0.003    0.000 datetimes.py:286(_simple_new)\n",
      "      792    0.004    0.000    0.075    0.000 datetimes.py:299(_from_sequence)\n",
      "     3960    0.001    0.000    0.001    0.000 datetimes.py:478(dtype)\n",
      "      792    0.000    0.000    0.000    0.000 datetimes.py:58(tz_to_dtype)\n",
      "     3992    0.004    0.000    0.012    0.000 dtypes.py:1119(is_dtype)\n",
      "     5578    0.006    0.000    0.017    0.000 dtypes.py:906(is_dtype)\n",
      "      100    0.002    0.000    0.168    0.002 frame.py:2869(__getitem__)\n",
      "      200    0.000    0.000    0.000    0.000 frame.py:421(_constructor)\n",
      "      201    0.001    0.000    0.002    0.000 frame.py:441(__init__)\n",
      "      398    0.000    0.000    0.000    0.000 frame.py:568(axes)\n",
      "      200    0.000    0.000    0.001    0.000 frame.py:585(shape)\n",
      "      100    0.001    0.000    5.251    0.053 frame.py:7614(append)\n",
      "      396    0.000    0.000    0.003    0.000 fromnumeric.py:55(_wrapfunc)\n",
      "      396    0.000    0.000    0.000    0.000 fromnumeric.py:993(_argsort_dispatcher)\n",
      "      396    0.001    0.000    0.003    0.000 fromnumeric.py:997(argsort)\n",
      "      100    0.000    0.000    0.000    0.000 frozen.py:66(__getitem__)\n",
      "      100    0.000    0.000    0.000    0.000 function.py:48(__call__)\n",
      "   137263    0.029    0.000    0.039    0.000 generic.py:10(_check)\n",
      "      201    0.001    0.000    0.001    0.000 generic.py:195(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 generic.py:232(attrs)\n",
      "       99    0.000    0.000    0.000    0.000 generic.py:3250(_clear_item_cache)\n",
      "      100    0.001    0.000    0.111    0.001 generic.py:3256(take)\n",
      "      100    0.000    0.000    0.117    0.001 generic.py:3355(_take_with_is_copy)\n",
      "      999    0.000    0.000    0.000    0.000 generic.py:365(_get_axis_number)\n",
      "      599    0.001    0.000    0.001    0.000 generic.py:377(_get_axis)\n",
      "      300    0.000    0.000    0.000    0.000 generic.py:382(_get_block_manager_axis)\n",
      "      400    0.000    0.000    0.000    0.000 generic.py:471(ndim)\n",
      "      200    0.000    0.000    0.001    0.000 generic.py:5095(__finalize__)\n",
      "      300    0.291    0.001    0.291    0.001 generic.py:5141(__setattr__)\n",
      "      300    0.001    0.000    1.938    0.006 generic.py:5197(_protect_consolidate)\n",
      "      300    0.000    0.000    1.938    0.006 generic.py:5208(_consolidate_inplace)\n",
      "      300    0.001    0.000    1.937    0.006 generic.py:5211(f)\n",
      "      200    0.001    0.000    1.938    0.010 generic.py:5216(_consolidate)\n",
      "      100    0.001    0.000    0.002    0.000 indexers.py:210(maybe_convert_indices)\n",
      "      100    0.001    0.000    0.045    0.000 indexing.py:1208(_get_listlike_indexer)\n",
      "      100    0.001    0.000    0.003    0.000 indexing.py:1257(_validate_read_indexer)\n",
      "      100    0.000    0.000    0.000    0.000 indexing.py:2126(convert_to_index_sliceable)\n",
      "      100    0.000    0.000    0.000    0.000 indexing.py:237(loc)\n",
      "      100    0.000    0.000    0.001    0.000 inference.py:185(is_array_like)\n",
      "      806    0.000    0.000    0.001    0.000 inference.py:322(is_hashable)\n",
      "      100    0.001    0.000    0.102    0.001 managers.py:1238(reindex_indexer)\n",
      "      100    0.010    0.000    0.100    0.001 managers.py:1300(_slice_take_blocks_ax0)\n",
      "      300    0.002    0.000    0.011    0.000 managers.py:132(__init__)\n",
      "      300    0.000    0.000    0.001    0.000 managers.py:138(<listcomp>)\n",
      "      100    0.001    0.000    0.108    0.001 managers.py:1427(take)\n",
      "      100    0.000    0.000    0.001    0.000 managers.py:156(from_blocks)\n",
      "      299    0.000    0.000    0.006    0.000 managers.py:163(blknos)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1675(create_block_manager_from_arrays)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1680(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1715(form_blocks)\n",
      "      299    0.000    0.000    0.000    0.000 managers.py:179(blklocs)\n",
      "       99    0.003    0.000    1.629    0.016 managers.py:1889(_consolidate)\n",
      "     3564    0.001    0.000    0.023    0.000 managers.py:1894(<lambda>)\n",
      "      693    0.924    0.001    1.601    0.002 managers.py:1906(_merge_blocks)\n",
      "      396    0.002    0.000    0.002    0.000 managers.py:1921(<listcomp>)\n",
      "      396    0.000    0.000    0.000    0.000 managers.py:1922(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 managers.py:2015(_preprocess_slice_or_indexer)\n",
      "      997    0.002    0.000    0.005    0.000 managers.py:212(shape)\n",
      "     2991    0.001    0.000    0.003    0.000 managers.py:214(<genexpr>)\n",
      "     4782    0.001    0.000    0.001    0.000 managers.py:216(ndim)\n",
      "      299    0.000    0.000    0.000    0.000 managers.py:233(_is_single_block)\n",
      "      199    0.006    0.000    0.013    0.000 managers.py:238(_rebuild_blknos_and_blklocs)\n",
      "      200    0.000    0.000    0.000    0.000 managers.py:259(items)\n",
      "      200    0.002    0.000    0.007    0.000 managers.py:321(_verify_integrity)\n",
      "     3782    0.001    0.000    0.002    0.000 managers.py:323(<genexpr>)\n",
      "      600    0.000    0.000    0.003    0.000 managers.py:675(is_consolidated)\n",
      "      299    0.001    0.000    0.003    0.000 managers.py:683(_consolidate_check)\n",
      "      299    0.001    0.000    0.002    0.000 managers.py:684(<listcomp>)\n",
      "      300    0.001    0.000    1.645    0.005 managers.py:961(consolidate)\n",
      "      300    0.001    0.000    1.638    0.005 managers.py:977(_consolidate_inplace)\n",
      "     4379    0.005    0.000    0.668    0.000 missing.py:130(_isna)\n",
      "     2388    0.022    0.000    0.657    0.000 missing.py:193(_isna_ndarraylike)\n",
      "     1194    0.008    0.000    0.600    0.001 missing.py:235(_isna_string_dtype)\n",
      "      498    0.002    0.000    0.014    0.000 missing.py:358(array_equivalent)\n",
      "      498    0.001    0.000    0.004    0.000 missing.py:456(_array_equivalent_object)\n",
      "     4379    0.002    0.000    0.670    0.000 missing.py:47(isna)\n",
      "      100    0.000    0.000    0.000    0.000 missing.py:665(clean_reindex_fill_method)\n",
      "      100    0.000    0.000    0.000    0.000 missing.py:75(clean_fill_method)\n",
      "     2574    0.000    0.000    0.000    0.000 multiarray.py:145(concatenate)\n",
      "      200    0.000    0.000    0.000    0.000 multiarray.py:469(can_cast)\n",
      "      398    0.000    0.000    0.000    0.000 multiarray.py:584(min_scalar_type)\n",
      "      100    0.000    0.000    0.000    0.000 numeric.py:81(_validate_dtype)\n",
      "    23862    0.009    0.000    0.013    0.000 numerictypes.py:293(issubclass_)\n",
      "    11931    0.009    0.000    0.023    0.000 numerictypes.py:365(issubdtype)\n",
      "     1000    0.000    0.000    0.001    0.000 numerictypes.py:578(_can_coerce_all)\n",
      "      500    0.001    0.000    0.003    0.000 numerictypes.py:602(find_common_type)\n",
      "      500    0.001    0.000    0.001    0.000 numerictypes.py:654(<listcomp>)\n",
      "      500    0.000    0.000    0.000    0.000 numerictypes.py:655(<listcomp>)\n",
      "      100    0.000    0.000    0.001    0.000 range.py:134(_simple_new)\n",
      "     1394    0.001    0.000    0.001    0.000 range.py:687(__len__)\n",
      "      100    0.001    0.000    0.003    0.000 range.py:86(__new__)\n",
      "      396    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
      "      396    0.000    0.000    0.001    0.000 shape_base.py:220(_vhstack_dispatcher)\n",
      "      396    0.001    0.000    0.643    0.002 shape_base.py:224(vstack)\n",
      "      396    0.000    0.000    0.000    0.000 shape_base.py:79(_atleast_2d_dispatcher)\n",
      "      396    0.001    0.000    0.002    0.000 shape_base.py:83(atleast_2d)\n",
      "     1790    0.001    0.000    0.001    0.000 {built-in method __new__ of type object at 0x2adbaa7c0c20}\n",
      "      602    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
      "     6992    0.004    0.000    0.725    0.000 {built-in method builtins.all}\n",
      "     6939    0.006    0.000    0.034    0.000 {built-in method builtins.any}\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    5.739    5.739 {built-in method builtins.exec}\n",
      "   216628    0.018    0.000    0.018    0.000 {built-in method builtins.getattr}\n",
      "    20266    0.003    0.000    0.003    0.000 {built-in method builtins.hasattr}\n",
      "      806    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "      398    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "   290334    0.057    0.000    0.096    0.000 {built-in method builtins.isinstance}\n",
      "   127943    0.014    0.000    0.014    0.000 {built-in method builtins.issubclass}\n",
      "57387/54493    0.010    0.000    0.012    0.000 {built-in method builtins.len}\n",
      "     4870    0.002    0.000    0.002    0.000 {built-in method builtins.max}\n",
      "     1782    0.001    0.000    0.001    0.000 {built-in method builtins.min}\n",
      "     3762    0.001    0.000    0.001    0.000 {built-in method builtins.next}\n",
      "       99    0.001    0.000    0.011    0.000 {built-in method builtins.sorted}\n",
      "      500    0.001    0.000    0.003    0.000 {built-in method builtins.sum}\n",
      "     1394    0.002    0.000    0.002    0.000 {built-in method numpy.arange}\n",
      "     8368    0.010    0.000    0.010    0.000 {built-in method numpy.array}\n",
      "4360/3568    1.263    0.000    1.271    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     4168    0.002    0.000    0.002    0.000 {built-in method numpy.datetime_data}\n",
      "     5479    0.338    0.000    0.338    0.000 {built-in method numpy.empty}\n",
      "     1194    0.003    0.000    0.003    0.000 {built-in method pandas._libs.lib.is_bool_array}\n",
      "     1991    0.001    0.000    0.001    0.000 {built-in method pandas._libs.missing.checknull}\n",
      "     1194    0.586    0.000    0.586    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
      "      792    0.000    0.000    0.000    0.000 {built-in method pandas._libs.tslibs.offsets.to_offset}\n",
      "      792    0.000    0.000    0.000    0.000 {built-in method pandas._libs.tslibs.timezones.maybe_get_tz}\n",
      "      100    0.000    0.000    0.000    0.000 {function FrozenList.__getitem__ at 0x2adc24e3cdc0}\n",
      "     3963    0.001    0.000    0.001    0.000 {method 'add' of 'set' objects}\n",
      "     2388    0.002    0.000    0.015    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "     4081    0.003    0.000    0.015    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "    11643    0.002    0.000    0.002    0.000 {method 'append' of 'list' objects}\n",
      "      396    0.002    0.000    0.002    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "       99    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "     3782    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "      795    0.039    0.000    0.039    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      398    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
      "    16099    0.007    0.000    0.007    0.000 {method 'format' of 'str' objects}\n",
      "     4782    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}\n",
      "      100    0.003    0.000    0.003    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
      "     3184    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "      700    0.001    0.000    0.005    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "      597    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "     5772    0.005    0.000    0.005    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "     7269    0.028    0.000    0.028    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     1194    0.001    0.000    0.001    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "     2578    0.001    0.000    0.001    0.000 {method 'startswith' of 'str' objects}\n",
      "      100    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "      997    0.044    0.000    0.044    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "      796    0.001    0.000    0.001    0.000 {method 'to_datetime64' of 'pandas._libs.tslibs.nattype._NaT' objects}\n",
      "      796    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "     2985    0.001    0.000    0.001    0.000 {method 'values' of 'dict' objects}\n",
      "     4964    0.005    0.000    0.005    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "     4782    0.002    0.000    0.002    0.000 {pandas._libs.algos.ensure_int64}\n",
      "      996    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "     1197    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
      "      200    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
      "      498    0.135    0.000    0.135    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
      "      896    0.048    0.000    0.048    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
      "     1294    0.552    0.000    0.552    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "      100    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_2d_axis1_int8_int8}\n",
      "      299    0.000    0.000    0.000    0.000 {pandas._libs.internals.get_blkno_placements}\n",
      "      498    0.002    0.000    0.002    0.000 {pandas._libs.lib.array_equivalent_object}\n",
      "     1094    0.007    0.000    0.014    0.000 {pandas._libs.lib.infer_dtype}\n",
      "      400    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "     3185    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "      996    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "      302    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "      502    0.001    0.000    0.002    0.000 {pandas._libs.lib.is_list_like}\n",
      "     8558    0.002    0.000    0.002    0.000 {pandas._libs.lib.is_scalar}\n",
      "      100    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run('appendtest(df_test, 100)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         727720 function calls (726117 primitive calls) in 0.473 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      200    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(can_cast)\n",
      "       19    0.000    0.000    0.015    0.001 <__array_function__ internals>:2(concatenate)\n",
      "      200    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(min_scalar_type)\n",
      "     4118    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "        1    0.000    0.000    0.450    0.450 <ipython-input-13-83d7805a51aa>:2(concattest)\n",
      "        1    0.023    0.023    0.472    0.472 <string>:1(<module>)\n",
      "     3999    0.001    0.000    0.005    0.000 _asarray.py:16(asarray)\n",
      "      400    0.001    0.000    0.002    0.000 _asarray.py:223(require)\n",
      "      400    0.000    0.000    0.000    0.000 _asarray.py:300(<setcomp>)\n",
      "      200    0.000    0.000    0.000    0.000 _asarray.py:88(asanyarray)\n",
      "     1800    0.001    0.000    0.002    0.000 _dtype.py:190(_datetime_metadata_str)\n",
      "     7600    0.004    0.000    0.014    0.000 _dtype.py:319(_name_includes_bit_suffix)\n",
      "     7600    0.010    0.000    0.030    0.000 _dtype.py:333(_name_get)\n",
      "     7600    0.002    0.000    0.002    0.000 _dtype.py:36(_kind_name)\n",
      "      400    0.000    0.000    0.002    0.000 _dtype.py:46(__str__)\n",
      "      500    0.000    0.000    0.000    0.000 _internal.py:830(npy_ctypes_check)\n",
      "      700    0.000    0.000    0.004    0.000 _methods.py:28(_amax)\n",
      "      100    0.000    0.000    0.001    0.000 _methods.py:36(_sum)\n",
      "     2200    0.001    0.000    0.004    0.000 _methods.py:44(_any)\n",
      "     1200    0.000    0.000    0.003    0.000 _methods.py:47(_all)\n",
      "      404    0.000    0.000    0.001    0.000 _mixins.py:70(shape)\n",
      "      404    0.000    0.000    0.001    0.000 _mixins.py:77(ndim)\n",
      "      100    0.000    0.000    0.000    0.000 _validators.py:208(validate_bool_kwarg)\n",
      "      207    0.000    0.000    0.000    0.000 abc.py:96(__instancecheck__)\n",
      "      500    0.001    0.000    0.005    0.000 algorithms.py:1327(wrapper)\n",
      "      600    0.001    0.000    0.014    0.000 algorithms.py:1370(_take_nd_object)\n",
      "     2400    0.009    0.000    0.033    0.000 algorithms.py:1487(_get_take_nd_function)\n",
      "      600    0.000    0.000    0.014    0.000 algorithms.py:1514(func2)\n",
      "     2400    0.043    0.000    0.191    0.000 algorithms.py:1616(take_nd)\n",
      "        1    0.000    0.000    0.003    0.003 api.py:109(_get_combined_index)\n",
      "        1    0.000    0.000    0.003    0.003 api.py:161(union_indexes)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:233(_sanitize_and_check)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:254(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:271(get_consensus_names)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:289(<setcomp>)\n",
      "        1    0.000    0.000    0.003    0.003 api.py:65(get_objs_combined_axis)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:91(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:95(_get_distinct_objs)\n",
      "      506    0.000    0.000    0.000    0.000 base.py:1175(name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1193(_validate_names)\n",
      "      101    0.000    0.000    0.000    0.000 base.py:1213(_get_names)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1216(_set_names)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1246(set_names)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1324(rename)\n",
      "      101    0.000    0.000    0.000    0.000 base.py:1378(nlevels)\n",
      "      100    0.000    0.000    0.001    0.000 base.py:1685(is_boolean)\n",
      "      100    0.000    0.000    0.001    0.000 base.py:2000(inferred_type)\n",
      "    14365    0.005    0.000    0.026    0.000 base.py:256(is_dtype)\n",
      "  400/200    0.004    0.000    0.023    0.000 base.py:293(__new__)\n",
      "      100    0.001    0.000    0.016    0.000 base.py:2957(get_indexer)\n",
      "      100    0.000    0.000    0.002    0.000 base.py:3194(_convert_listlike_indexer)\n",
      "      100    0.000    0.000    0.002    0.000 base.py:3216(_convert_arr_indexer)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:3247(_convert_list_indexer)\n",
      "      100    0.000    0.000    0.015    0.000 base.py:3291(reindex)\n",
      "     1201    0.000    0.000    0.000    0.000 base.py:3870(_values)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:3896(_get_engine_target)\n",
      "    16017    0.007    0.000    0.011    0.000 base.py:413(find)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4133(append)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4156(<setcomp>)\n",
      "      399    0.001    0.000    0.012    0.000 base.py:4196(equals)\n",
      "      304    0.000    0.000    0.001    0.000 base.py:463(_simple_new)\n",
      "      100    0.000    0.000    0.016    0.000 base.py:4700(get_indexer_for)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:4717(_maybe_promote)\n",
      "      103    0.000    0.000    0.000    0.000 base.py:498(_shallow_copy)\n",
      "      399    0.000    0.000    0.000    0.000 base.py:520(is_)\n",
      "      304    0.000    0.000    0.000    0.000 base.py:544(_reset_identity)\n",
      "      403    0.000    0.000    0.023    0.000 base.py:5559(ensure_index)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:5623(ensure_has_len)\n",
      "      401    0.000    0.000    0.001    0.000 base.py:5656(maybe_extract_name)\n",
      "      703    0.000    0.000    0.000    0.000 base.py:567(__len__)\n",
      "      200    0.000    0.000    0.001    0.000 base.py:5672(_maybe_cast_with_dtype)\n",
      "      200    0.000    0.000    0.003    0.000 base.py:5726(_maybe_cast_data_without_dtype)\n",
      "      300    0.000    0.000    0.000    0.000 base.py:590(dtype)\n",
      "      100    0.000    0.000    0.001    0.000 base.py:701(take)\n",
      "      100    0.000    0.000    0.000    0.000 base.py:723(_assert_take_fillable)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:793(copy)\n",
      "      700    0.002    0.000    0.106    0.000 blocks.py:1238(take_nd)\n",
      "      718    0.001    0.000    0.002    0.000 blocks.py:124(__init__)\n",
      "      718    0.000    0.000    0.000    0.000 blocks.py:135(_check_ndim)\n",
      "      100    0.000    0.000    0.000    0.000 blocks.py:2012(fill_value)\n",
      "      104    0.000    0.000    0.001    0.000 blocks.py:2048(__init__)\n",
      "      400    0.000    0.000    0.000    0.000 blocks.py:2052(_can_hold_na)\n",
      "      104    0.000    0.000    0.000    0.000 blocks.py:2056(_maybe_coerce_values)\n",
      "      300    0.000    0.000    0.001    0.000 blocks.py:213(get_values)\n",
      "      900    0.000    0.000    0.000    0.000 blocks.py:229(fill_value)\n",
      "     3836    0.000    0.000    0.000    0.000 blocks.py:233(mgr_locs)\n",
      "      718    0.000    0.000    0.000    0.000 blocks.py:237(mgr_locs)\n",
      "      106    0.000    0.000    0.001    0.000 blocks.py:2374(__init__)\n",
      "      600    0.001    0.000    0.002    0.000 blocks.py:2380(is_bool)\n",
      "      700    0.001    0.000    0.003    0.000 blocks.py:256(make_block_same_class)\n",
      "       18    0.000    0.000    0.000    0.000 blocks.py:2655(get_block_type)\n",
      "       18    0.000    0.000    0.001    0.000 blocks.py:2701(make_block)\n",
      "       15    0.000    0.000    0.000    0.000 blocks.py:276(__len__)\n",
      "       18    0.000    0.000    0.000    0.000 blocks.py:311(shape)\n",
      "     2900    0.001    0.000    0.001    0.000 blocks.py:315(dtype)\n",
      "     1700    0.006    0.000    0.021    0.000 cast.py:442(maybe_promote)\n",
      "     1700    0.001    0.000    0.005    0.000 cast.py:598(_ensure_dtype_type)\n",
      "      600    0.000    0.000    0.001    0.000 common.py:1025(is_datetime_or_timedelta_dtype)\n",
      "      600    0.000    0.000    0.002    0.000 common.py:1180(needs_i8_conversion)\n",
      "      303    0.000    0.000    0.001    0.000 common.py:1223(is_numeric_dtype)\n",
      "      600    0.000    0.000    0.001    0.000 common.py:1265(is_string_like_dtype)\n",
      "      600    0.000    0.000    0.000    0.000 common.py:1293(<lambda>)\n",
      "     1505    0.001    0.000    0.002    0.000 common.py:1296(is_float_dtype)\n",
      "     1600    0.001    0.000    0.006    0.000 common.py:1330(is_bool_dtype)\n",
      "    16017    0.009    0.000    0.023    0.000 common.py:1460(is_extension_array_dtype)\n",
      "     2599    0.001    0.000    0.014    0.000 common.py:1541(_is_dtype)\n",
      "     5801    0.002    0.000    0.002    0.000 common.py:1565(_get_dtype)\n",
      "     6606    0.003    0.000    0.005    0.000 common.py:1600(_is_dtype_type)\n",
      "      600    0.000    0.000    0.000    0.000 common.py:1733(pandas_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:176(not_none)\n",
      "     5303    0.001    0.000    0.001    0.000 common.py:178(classes)\n",
      "      101    0.000    0.000    0.000    0.000 common.py:180(<genexpr>)\n",
      "     5303    0.001    0.000    0.002    0.000 common.py:180(<lambda>)\n",
      "     1303    0.000    0.000    0.000    0.000 common.py:183(classes_and_not_datetimelike)\n",
      "     1303    0.000    0.000    0.001    0.000 common.py:188(<lambda>)\n",
      "     2998    0.002    0.000    0.004    0.000 common.py:194(is_object_dtype)\n",
      "      100    0.000    0.000    0.000    0.000 common.py:197(any_not_none)\n",
      "      200    0.000    0.000    0.000    0.000 common.py:201(<genexpr>)\n",
      "      500    0.001    0.000    0.004    0.000 common.py:218(asarray_tuplesafe)\n",
      "     3518    0.003    0.000    0.006    0.000 common.py:224(is_sparse)\n",
      "      100    0.000    0.000    0.000    0.000 common.py:329(apply_if_callable)\n",
      "     3100    0.001    0.000    0.001    0.000 common.py:348(is_datetime64_dtype)\n",
      "     5218    0.002    0.000    0.012    0.000 common.py:381(is_datetime64tz_dtype)\n",
      "     3100    0.001    0.000    0.001    0.000 common.py:422(is_timedelta64_dtype)\n",
      "     2417    0.001    0.000    0.007    0.000 common.py:456(is_period_dtype)\n",
      "     1813    0.001    0.000    0.005    0.000 common.py:492(is_interval_dtype)\n",
      "     5517    0.002    0.000    0.012    0.000 common.py:530(is_categorical_dtype)\n",
      "     1999    0.001    0.000    0.014    0.000 common.py:566(is_string_dtype)\n",
      "     1999    0.001    0.000    0.012    0.000 common.py:595(condition)\n",
      "      999    0.001    0.000    0.011    0.000 common.py:598(is_excluded_dtype)\n",
      "     3996    0.001    0.000    0.010    0.000 common.py:603(<genexpr>)\n",
      "      801    0.001    0.000    0.001    0.000 common.py:608(is_dtype_equal)\n",
      "      200    0.000    0.000    0.000    0.000 common.py:696(is_integer_dtype)\n",
      "      400    0.000    0.000    0.001    0.000 common.py:750(is_signed_integer_dtype)\n",
      "      400    0.000    0.000    0.001    0.000 common.py:806(is_unsigned_integer_dtype)\n",
      "      800    0.000    0.000    0.000    0.000 common.py:905(is_datetime64_any_dtype)\n",
      "      100    0.000    0.000    0.002    0.000 common.py:97(is_bool_indexer)\n",
      "       18    0.000    0.000    0.068    0.004 concat.py:110(concat_compat)\n",
      "     1800    0.000    0.000    0.000    0.000 concat.py:128(is_nonempty)\n",
      "       18    0.000    0.000    0.001    0.000 concat.py:139(<listcomp>)\n",
      "       36    0.000    0.000    0.000    0.000 concat.py:144(<genexpr>)\n",
      "       18    0.000    0.000    0.000    0.000 concat.py:147(<setcomp>)\n",
      "     1818    0.000    0.000    0.002    0.000 concat.py:148(<genexpr>)\n",
      "     1800    0.000    0.000    0.000    0.000 concat.py:174(__init__)\n",
      "     1500    0.003    0.000    0.007    0.000 concat.py:185(needs_filling)\n",
      "     1500    0.001    0.000    0.008    0.000 concat.py:194(dtype)\n",
      "     1800    0.004    0.000    0.054    0.000 concat.py:204(is_na)\n",
      "     1500    0.003    0.000    0.088    0.000 concat.py:233(get_reindexed_values)\n",
      "       18    0.003    0.000    0.021    0.001 concat.py:29(get_dtype_kinds)\n",
      "        1    0.000    0.000    0.004    0.004 concat.py:295(__init__)\n",
      "       15    0.000    0.000    0.177    0.012 concat.py:306(_concatenate_join_units)\n",
      "        1    0.007    0.007    0.260    0.260 concat.py:31(concatenate_block_managers)\n",
      "       15    0.001    0.000    0.089    0.006 concat.py:316(<listcomp>)\n",
      "     1515    0.000    0.000    0.000    0.000 concat.py:332(<genexpr>)\n",
      "       15    0.004    0.000    0.025    0.002 concat.py:351(_get_empty_dtype_and_na)\n",
      "        4    0.000    0.000    0.029    0.007 concat.py:364(concat_datetime)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:379(<listcomp>)\n",
      "        4    0.000    0.000    0.024    0.006 concat.py:382(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 concat.py:383(<setcomp>)\n",
      "        4    0.000    0.000    0.001    0.000 concat.py:392(<listcomp>)\n",
      "      400    0.001    0.000    0.024    0.000 concat.py:403(_wrap_datetimelike)\n",
      "        1    0.002    0.002    0.264    0.264 concat.py:456(get_result)\n",
      "       18    0.000    0.000    0.057    0.003 concat.py:465(_is_uniform_join_units)\n",
      "     1818    0.001    0.000    0.001    0.000 concat.py:476(<genexpr>)\n",
      "        1    0.000    0.000    0.010    0.010 concat.py:48(<listcomp>)\n",
      "     1818    0.002    0.000    0.056    0.000 concat.py:480(<genexpr>)\n",
      "      333    0.000    0.000    0.000    0.000 concat.py:483(<genexpr>)\n",
      "       15    0.000    0.000    0.000    0.000 concat.py:490(_is_uniform_reindex)\n",
      "       30    0.000    0.000    0.000    0.000 concat.py:493(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:511(_get_result_dim)\n",
      "        1    0.000    0.000    0.003    0.003 concat.py:517(_get_new_axes)\n",
      "        1    0.000    0.000    0.003    0.003 concat.py:519(<listcomp>)\n",
      "        1    0.000    0.000    0.003    0.003 concat.py:524(_get_comb_axis)\n",
      "       19    0.001    0.000    0.002    0.000 concat.py:525(_combine_concat_plans)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:534(_get_concat_axis)\n",
      "     1900    0.000    0.000    0.001    0.000 concat.py:550(_next_or_none)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:567(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:584(_maybe_check_integrity)\n",
      "        1    0.000    0.000    0.000    0.000 concat.py:591(_concat_indexes)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:66(<listcomp>)\n",
      "        1    0.000    0.000    0.268    0.268 concat.py:70(concat)\n",
      "      100    0.005    0.000    0.010    0.000 concat.py:87(_get_mgr_concatenation_plan)\n",
      "     3200    0.001    0.000    0.005    0.000 construction.py:339(extract_array)\n",
      "      400    0.001    0.000    0.022    0.000 construction.py:57(array)\n",
      "      400    0.000    0.000    0.000    0.000 datetimelike.py:1729(validate_inferred_freq)\n",
      "      400    0.000    0.000    0.000    0.000 datetimelike.py:1764(maybe_infer_freq)\n",
      "      404    0.000    0.000    0.000    0.000 datetimelike.py:464(_ndarray)\n",
      "      804    0.000    0.000    0.001    0.000 datetimelike.py:491(asi8)\n",
      "        4    0.000    0.000    0.004    0.001 datetimelike.py:671(_concat_same_type)\n",
      "        4    0.001    0.000    0.003    0.001 datetimelike.py:675(<setcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 datetimelike.py:682(<listcomp>)\n",
      "      400    0.002    0.000    0.012    0.000 datetimes.py:1871(sequence_to_dt64ns)\n",
      "      400    0.001    0.000    0.006    0.000 datetimes.py:2085(maybe_convert_dtype)\n",
      "      400    0.000    0.000    0.000    0.000 datetimes.py:2178(_validate_dt64_dtype)\n",
      "      800    0.000    0.000    0.000    0.000 datetimes.py:2220(validate_tz_from_dtype)\n",
      "      404    0.000    0.000    0.000    0.000 datetimes.py:286(_simple_new)\n",
      "      400    0.001    0.000    0.014    0.000 datetimes.py:299(_from_sequence)\n",
      "      824    0.000    0.000    0.000    0.000 datetimes.py:478(dtype)\n",
      "      400    0.000    0.000    0.000    0.000 datetimes.py:58(tz_to_dtype)\n",
      "     1613    0.001    0.000    0.004    0.000 dtypes.py:1119(is_dtype)\n",
      "     2217    0.001    0.000    0.006    0.000 dtypes.py:906(is_dtype)\n",
      "      100    0.001    0.000    0.181    0.002 frame.py:2869(__getitem__)\n",
      "      101    0.000    0.000    0.000    0.000 frame.py:421(_constructor)\n",
      "      101    0.000    0.000    0.000    0.000 frame.py:441(__init__)\n",
      "      200    0.000    0.000    0.000    0.000 frame.py:568(axes)\n",
      "      100    0.000    0.000    0.000    0.000 frame.py:585(shape)\n",
      "        1    0.000    0.000    0.000    0.000 frozen.py:66(__getitem__)\n",
      "      100    0.000    0.000    0.000    0.000 function.py:48(__call__)\n",
      "    61818    0.012    0.000    0.016    0.000 generic.py:10(_check)\n",
      "      101    0.000    0.000    0.000    0.000 generic.py:195(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 generic.py:232(attrs)\n",
      "      100    0.001    0.000    0.139    0.001 generic.py:3256(take)\n",
      "      100    0.000    0.000    0.143    0.001 generic.py:3355(_take_with_is_copy)\n",
      "      603    0.000    0.000    0.000    0.000 generic.py:365(_get_axis_number)\n",
      "      500    0.000    0.000    0.001    0.000 generic.py:377(_get_axis)\n",
      "      102    0.000    0.000    0.000    0.000 generic.py:382(_get_block_manager_axis)\n",
      "      102    0.000    0.000    0.000    0.000 generic.py:471(ndim)\n",
      "      101    0.000    0.000    0.000    0.000 generic.py:5095(__finalize__)\n",
      "      200    0.000    0.000    0.000    0.000 generic.py:5141(__setattr__)\n",
      "      200    0.000    0.000    0.001    0.000 generic.py:5197(_protect_consolidate)\n",
      "      200    0.000    0.000    0.001    0.000 generic.py:5208(_consolidate_inplace)\n",
      "      200    0.000    0.000    0.001    0.000 generic.py:5211(f)\n",
      "      100    0.000    0.000    0.001    0.000 generic.py:5216(_consolidate)\n",
      "      100    0.001    0.000    0.001    0.000 indexers.py:210(maybe_convert_indices)\n",
      "      100    0.000    0.000    0.035    0.000 indexing.py:1208(_get_listlike_indexer)\n",
      "      100    0.001    0.000    0.002    0.000 indexing.py:1257(_validate_read_indexer)\n",
      "      100    0.000    0.000    0.000    0.000 indexing.py:2126(convert_to_index_sliceable)\n",
      "      100    0.000    0.000    0.000    0.000 indexing.py:237(loc)\n",
      "      100    0.000    0.000    0.000    0.000 inference.py:185(is_array_like)\n",
      "      503    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\n",
      "      100    0.000    0.000    0.132    0.001 managers.py:1238(reindex_indexer)\n",
      "      100    0.007    0.000    0.131    0.001 managers.py:1300(_slice_take_blocks_ax0)\n",
      "      101    0.000    0.000    0.001    0.000 managers.py:132(__init__)\n",
      "      101    0.000    0.000    0.000    0.000 managers.py:138(<listcomp>)\n",
      "      100    0.001    0.000    0.137    0.001 managers.py:1427(take)\n",
      "      100    0.000    0.000    0.001    0.000 managers.py:156(from_blocks)\n",
      "      200    0.000    0.000    0.003    0.000 managers.py:163(blknos)\n",
      "      200    0.000    0.000    0.000    0.000 managers.py:179(blklocs)\n",
      "      100    0.000    0.000    0.000    0.000 managers.py:2015(_preprocess_slice_or_indexer)\n",
      "      501    0.001    0.000    0.002    0.000 managers.py:212(shape)\n",
      "     1503    0.000    0.000    0.001    0.000 managers.py:214(<genexpr>)\n",
      "      920    0.000    0.000    0.000    0.000 managers.py:216(ndim)\n",
      "      200    0.000    0.000    0.000    0.000 managers.py:233(_is_single_block)\n",
      "      100    0.001    0.000    0.003    0.000 managers.py:238(_rebuild_blknos_and_blklocs)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:259(items)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:321(_verify_integrity)\n",
      "       19    0.000    0.000    0.000    0.000 managers.py:323(<genexpr>)\n",
      "      400    0.000    0.000    0.000    0.000 managers.py:675(is_consolidated)\n",
      "      100    0.000    0.000    0.000    0.000 managers.py:683(_consolidate_check)\n",
      "      100    0.000    0.000    0.000    0.000 managers.py:684(<listcomp>)\n",
      "      200    0.000    0.000    0.000    0.000 managers.py:961(consolidate)\n",
      "      200    0.000    0.000    0.000    0.000 managers.py:977(_consolidate_inplace)\n",
      "     2300    0.002    0.000    0.043    0.000 missing.py:130(_isna)\n",
      "     1200    0.004    0.000    0.040    0.000 missing.py:193(_isna_ndarraylike)\n",
      "      600    0.001    0.000    0.022    0.000 missing.py:235(_isna_string_dtype)\n",
      "      399    0.001    0.000    0.008    0.000 missing.py:358(array_equivalent)\n",
      "      399    0.001    0.000    0.002    0.000 missing.py:456(_array_equivalent_object)\n",
      "     2300    0.001    0.000    0.044    0.000 missing.py:47(isna)\n",
      "      100    0.000    0.000    0.000    0.000 missing.py:665(clean_reindex_fill_method)\n",
      "      100    0.000    0.000    0.000    0.000 missing.py:75(clean_fill_method)\n",
      "       19    0.000    0.000    0.000    0.000 multiarray.py:145(concatenate)\n",
      "      200    0.000    0.000    0.000    0.000 multiarray.py:469(can_cast)\n",
      "      200    0.000    0.000    0.000    0.000 multiarray.py:584(min_scalar_type)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:105(_shallow_copy)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:50(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:81(_validate_dtype)\n",
      "    11800    0.004    0.000    0.006    0.000 numerictypes.py:293(issubclass_)\n",
      "     5900    0.004    0.000    0.010    0.000 numerictypes.py:365(issubdtype)\n",
      "       10    0.000    0.000    0.000    0.000 numerictypes.py:578(_can_coerce_all)\n",
      "        5    0.000    0.000    0.000    0.000 numerictypes.py:602(find_common_type)\n",
      "        5    0.000    0.000    0.000    0.000 numerictypes.py:654(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 numerictypes.py:655(<listcomp>)\n",
      "      100    0.000    0.000    0.000    0.000 range.py:153(_data)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:634(_concat)\n",
      "      101    0.000    0.000    0.000    0.000 range.py:643(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:649(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:671(<listcomp>)\n",
      "      700    0.000    0.000    0.000    0.000 range.py:687(__len__)\n",
      "      708    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x2adbaa7c0c20}\n",
      "      207    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       70    0.000    0.000    0.057    0.001 {built-in method builtins.all}\n",
      "     1150    0.001    0.000    0.014    0.000 {built-in method builtins.any}\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    0.473    0.473 {built-in method builtins.exec}\n",
      "    98718    0.008    0.000    0.008    0.000 {built-in method builtins.getattr}\n",
      "     9918    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "      503    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "   142437    0.023    0.000    0.040    0.000 {built-in method builtins.isinstance}\n",
      "    61601    0.006    0.000    0.006    0.000 {built-in method builtins.issubclass}\n",
      "16054/14651    0.002    0.000    0.002    0.000 {built-in method builtins.len}\n",
      "     1918    0.001    0.000    0.001    0.000 {built-in method builtins.max}\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "     1900    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "      101    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "      700    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "     4799    0.005    0.000    0.005    0.000 {built-in method numpy.array}\n",
      "      419    0.016    0.000    0.016    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     1800    0.001    0.000    0.001    0.000 {built-in method numpy.datetime_data}\n",
      "     3200    0.021    0.000    0.021    0.000 {built-in method numpy.empty}\n",
      "      600    0.001    0.000    0.001    0.000 {built-in method pandas._libs.lib.is_bool_array}\n",
      "     1100    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.checknull}\n",
      "      600    0.019    0.000    0.019    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
      "      400    0.000    0.000    0.000    0.000 {built-in method pandas._libs.tslibs.offsets.to_offset}\n",
      "      400    0.000    0.000    0.000    0.000 {built-in method pandas._libs.tslibs.timezones.maybe_get_tz}\n",
      "        1    0.000    0.000    0.000    0.000 {function FrozenList.__getitem__ at 0x2adc24e3cdc0}\n",
      "     2000    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "     1200    0.000    0.000    0.004    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "     2200    0.001    0.000    0.005    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "     4318    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "     1803    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "      400    0.001    0.000    0.001    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
      "     7700    0.003    0.000    0.003    0.000 {method 'format' of 'str' objects}\n",
      "     3000    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "      100    0.001    0.000    0.001    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
      "     1600    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      700    0.000    0.000    0.005    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "      300    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "     3198    0.002    0.000    0.002    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "     4200    0.011    0.000    0.011    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      418    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "      100    0.000    0.000    0.001    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "      700    0.013    0.000    0.013    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'to_datetime64' of 'pandas._libs.tslibs.nattype._NaT' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "     1500    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "     2208    0.001    0.000    0.001    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "     3000    0.001    0.000    0.001    0.000 {pandas._libs.algos.ensure_int64}\n",
      "      798    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "      900    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
      "      200    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
      "      300    0.007    0.000    0.007    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
      "      500    0.003    0.000    0.003    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
      "      700    0.035    0.000    0.035    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "      100    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_2d_axis1_int8_int8}\n",
      "      200    0.000    0.000    0.000    0.000 {pandas._libs.internals.get_blkno_placements}\n",
      "      399    0.001    0.000    0.001    0.000 {pandas._libs.lib.array_equivalent_object}\n",
      "      700    0.003    0.000    0.006    0.000 {pandas._libs.lib.infer_dtype}\n",
      "      300    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "     1700    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "      600    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "      300    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "      206    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "     4400    0.001    0.000    0.001    0.000 {pandas._libs.lib.is_scalar}\n",
      "      100    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run('concattest(df_test, 100)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         76799 function calls (76753 primitive calls) in 0.772 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       40    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(copyto)\n",
      "       44    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "        1    0.011    0.011    0.719    0.719 <ipython-input-14-dd9b0dc6fdcb>:3(listtest)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-14-dd9b0dc6fdcb>:4(<dictcomp>)\n",
      "        1    0.053    0.053    0.772    0.772 <string>:1(<module>)\n",
      "       42    0.000    0.000    0.000    0.000 _asarray.py:16(asarray)\n",
      "        3    0.000    0.000    0.000    0.000 _asarray.py:223(require)\n",
      "        3    0.000    0.000    0.000    0.000 _asarray.py:300(<setcomp>)\n",
      "       18    0.000    0.000    0.000    0.000 _dtype.py:319(_name_includes_bit_suffix)\n",
      "       18    0.000    0.000    0.000    0.000 _dtype.py:333(_name_get)\n",
      "       18    0.000    0.000    0.000    0.000 _dtype.py:36(_kind_name)\n",
      "        2    0.000    0.000    0.000    0.000 _internal.py:830(npy_ctypes_check)\n",
      "      146    0.000    0.000    0.000    0.000 abc.py:96(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1182(name)\n",
      "     4000    0.000    0.000    0.000    0.000 base.py:1378(nlevels)\n",
      "      221    0.000    0.000    0.000    0.000 base.py:256(is_dtype)\n",
      "      3/1    0.000    0.000    0.000    0.000 base.py:293(__new__)\n",
      "     4000    0.002    0.000    0.002    0.000 base.py:4036(__contains__)\n",
      "       40    0.000    0.000    0.000    0.000 base.py:4083(__getitem__)\n",
      "      131    0.000    0.000    0.000    0.000 base.py:413(find)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4196(equals)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:424(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:463(_simple_new)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:520(is_)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:544(_reset_identity)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:5559(ensure_index)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5650(default_index)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:5656(maybe_extract_name)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:567(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5672(_maybe_cast_with_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5726(_maybe_cast_data_without_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:124(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:135(_check_ndim)\n",
      "     4000    0.001    0.000    0.001    0.000 blocks.py:190(external_values)\n",
      "        6    0.000    0.000    0.000    0.000 blocks.py:233(mgr_locs)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:237(mgr_locs)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:2374(__init__)\n",
      "       43    0.000    0.000    0.001    0.000 blocks.py:2655(get_block_type)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:2701(make_block)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:311(shape)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:315(dtype)\n",
      "       25    0.000    0.000    0.001    0.000 cast.py:1201(maybe_infer_to_datetimelike)\n",
      "       40    0.000    0.000    0.001    0.000 cast.py:1310(maybe_cast_to_datetime)\n",
      "       41    0.123    0.003    0.136    0.003 cast.py:1570(construct_1d_object_array_from_listlike)\n",
      "       40    0.007    0.000    0.412    0.010 cast.py:88(maybe_convert_platform)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:1296(is_float_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1330(is_bool_dtype)\n",
      "      131    0.000    0.000    0.000    0.000 common.py:1460(is_extension_array_dtype)\n",
      "       40    0.000    0.000    0.000    0.000 common.py:149(cast_scalar_indexer)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:150(ensure_python_int)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1565(_get_dtype)\n",
      "       93    0.000    0.000    0.000    0.000 common.py:1600(_is_dtype_type)\n",
      "       28    0.000    0.000    0.000    0.000 common.py:1733(pandas_dtype)\n",
      "       88    0.000    0.000    0.000    0.000 common.py:178(classes)\n",
      "       88    0.000    0.000    0.000    0.000 common.py:180(<lambda>)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:183(classes_and_not_datetimelike)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:188(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:190(all_none)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:194(<genexpr>)\n",
      "       82    0.000    0.000    0.000    0.000 common.py:194(is_object_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:218(asarray_tuplesafe)\n",
      "       43    0.000    0.000    0.000    0.000 common.py:224(is_sparse)\n",
      "       40    0.000    0.000    0.000    0.000 common.py:274(maybe_iterable_to_list)\n",
      "     4000    0.001    0.000    0.001    0.000 common.py:329(apply_if_callable)\n",
      "       83    0.000    0.000    0.000    0.000 common.py:381(is_datetime64tz_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:422(is_timedelta64_dtype)\n",
      "       49    0.000    0.000    0.000    0.000 common.py:456(is_period_dtype)\n",
      "       49    0.000    0.000    0.000    0.000 common.py:492(is_interval_dtype)\n",
      "       49    0.000    0.000    0.000    0.000 common.py:530(is_categorical_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:696(is_integer_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:750(is_signed_integer_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:806(is_unsigned_integer_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:905(is_datetime64_any_dtype)\n",
      "        1    0.006    0.006    0.502    0.502 construction.py:237(init_dict)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:274(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:277(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:280(<listcomp>)\n",
      "        1    0.012    0.012    0.474    0.474 construction.py:329(_homogenize)\n",
      "       40    0.000    0.000    0.000    0.000 construction.py:339(extract_array)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:360(extract_index)\n",
      "       40    0.021    0.001    0.463    0.012 construction.py:390(sanitize_array)\n",
      "        1    0.000    0.000    0.495    0.495 construction.py:60(arrays_to_mgr)\n",
      "       46    0.000    0.000    0.000    0.000 dtypes.py:1119(is_dtype)\n",
      "       46    0.000    0.000    0.000    0.000 dtypes.py:906(is_dtype)\n",
      "        1    0.000    0.000    0.502    0.502 frame.py:1230(from_dict)\n",
      "     4000    0.008    0.000    0.015    0.000 frame.py:2869(__getitem__)\n",
      "        1    0.000    0.000    0.502    0.502 frame.py:441(__init__)\n",
      "     1128    0.000    0.000    0.000    0.000 generic.py:10(_check)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:195(__init__)\n",
      "     4000    0.001    0.000    0.002    0.000 generic.py:3532(_get_item_cache)\n",
      "     4005    0.001    0.000    0.001    0.000 inference.py:322(is_hashable)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:132(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:138(<listcomp>)\n",
      "     4000    0.001    0.000    0.001    0.000 managers.py:1575(_block)\n",
      "     4000    0.002    0.000    0.003    0.000 managers.py:1609(external_values)\n",
      "        1    0.000    0.000    0.021    0.021 managers.py:1675(create_block_manager_from_arrays)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1680(<genexpr>)\n",
      "        1    0.000    0.000    0.021    0.021 managers.py:1715(form_blocks)\n",
      "        1    0.000    0.000    0.015    0.015 managers.py:1812(_simple_blockify)\n",
      "        2    0.000    0.000    0.005    0.003 managers.py:1827(_multi_blockify)\n",
      "       23    0.000    0.000    0.000    0.000 managers.py:1830(<lambda>)\n",
      "        3    0.012    0.004    0.020    0.007 managers.py:1843(_stack_arrays)\n",
      "       40    0.000    0.000    0.000    0.000 managers.py:1846(_asarray_compat)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1852(_shape_compat)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:212(shape)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:214(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:216(ndim)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:259(items)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:321(_verify_integrity)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:323(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:675(is_consolidated)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:683(_consolidate_check)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:684(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:977(_consolidate_inplace)\n",
      "       40    0.000    0.000    0.000    0.000 multiarray.py:1043(copyto)\n",
      "       40    0.000    0.000    0.001    0.000 numeric.py:283(full)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:81(_validate_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:134(_simple_new)\n",
      "       41    0.000    0.000    0.000    0.000 range.py:687(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:86(__new__)\n",
      "     4000    0.001    0.000    0.004    0.000 series.py:498(values)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x2adbaa7c0c20}\n",
      "      146    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "     4000    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    0.772    0.772 {built-in method builtins.exec}\n",
      "     1647    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "      117    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "     8005    0.001    0.000    0.001    0.000 {built-in method builtins.hash}\n",
      "     2064    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "      496    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "  298/254    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "      111    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "       40    0.001    0.000    0.001    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "       84    0.020    0.000    0.020    0.000 {built-in method numpy.empty}\n",
      "      122    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "     4003    0.065    0.000    0.065    0.000 {method 'extend' of 'list' objects}\n",
      "     4000    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "     4000    0.123    0.000    0.123    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "       17    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "       17    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
      "       18    0.028    0.002    0.028    0.002 {pandas._libs.lib.infer_dtype}\n",
      "       40    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "       66    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "       43    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "     4000    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "       40    0.268    0.007    0.269    0.007 {pandas._libs.lib.maybe_convert_objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run('listtest(df_test, 100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1年分のデータを読んでみる\n",
    "実行には相当な時間がかかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.5 s ± 187 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# 単純にファイルを読む速度\n",
    "def readtest2(files):\n",
    "    for file in files:\n",
    "        df_tmp = pd.read_json(file, convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'records')\n",
    "        \n",
    "%timeit -r 3 df = readtest2(allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2 s ± 412 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# 全てのデータを1回のconcatで連結する\n",
    "def concattest2(files):\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        df_list.append(pd.read_json(file, convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'records'))\n",
    "    df = pd.concat(df_list)\n",
    "    return df\n",
    "\n",
    "%timeit -r 3 df = concattest2(allfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1年分のデータをまとめて保存する\n",
    "\n",
    "JSON、CSV、Pickleは、一部のデータのみが必要な場合でもファイル全体を読む必要があるので、巨大データの保存には向いていない。\n",
    "ParquetとPickleは読み書き共に速いので一時作業保存用に便利。解析には必要なデータのみを取り出せるSQLite3が便利。\n",
    "\n",
    "HDFはNoneを含むint型の列の取り扱いについて要検討。gp APIは問題ない(はず)が、satcat等の他のAPIにはそのようなデータが存在する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.8 s, sys: 425 ms, total: 28.3 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# テスト用のデータを準備する (欠損値のふるまいを調べるため、nullを含むダミーデータを末尾に追加しておく)\n",
    "df_list = []\n",
    "for file in allfiles:\n",
    "    df_list.append(pd.read_json(file, convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'records'))\n",
    "df_list.append(df_null)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n"
     ]
    }
   ],
   "source": [
    "# nullデータはfloat はnan、datetime64[ns]はNaT、それ以外はNoneとなる (read_jsonのdtypeにstr を指定すると \"None\" という文字列になってしまう)\n",
    "print(df.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCSDS_OMM_VERS                 object\n",
      "COMMENT                        object\n",
      "CREATION_DATE          datetime64[ns]\n",
      "ORIGINATOR                     object\n",
      "OBJECT_NAME                    object\n",
      "OBJECT_ID                      object\n",
      "CENTER_NAME                    object\n",
      "REF_FRAME                      object\n",
      "TIME_SYSTEM                    object\n",
      "MEAN_ELEMENT_THEORY            object\n",
      "EPOCH                  datetime64[ns]\n",
      "MEAN_MOTION                   float64\n",
      "ECCENTRICITY                  float64\n",
      "INCLINATION                   float64\n",
      "RA_OF_ASC_NODE                float64\n",
      "ARG_OF_PERICENTER             float64\n",
      "MEAN_ANOMALY                  float64\n",
      "EPHEMERIS_TYPE                   int8\n",
      "CLASSIFICATION_TYPE            object\n",
      "NORAD_CAT_ID                   uint32\n",
      "ELEMENT_SET_NO                 uint16\n",
      "REV_AT_EPOCH                   uint32\n",
      "BSTAR                         float64\n",
      "MEAN_MOTION_DOT               float64\n",
      "MEAN_MOTION_DDOT              float64\n",
      "SEMIMAJOR_AXIS                float64\n",
      "PERIOD                        float64\n",
      "APOAPSIS                      float64\n",
      "PERIAPSIS                     float64\n",
      "OBJECT_TYPE                    object\n",
      "RCS_SIZE                       object\n",
      "COUNTRY_CODE                   object\n",
      "LAUNCH_DATE            datetime64[ns]\n",
      "SITE                           object\n",
      "DECAY_DATE             datetime64[ns]\n",
      "FILE                           uint64\n",
      "GP_ID                          uint32\n",
      "TLE_LINE0                      object\n",
      "TLE_LINE1                      object\n",
      "TLE_LINE2                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CCSDS_OMM_VERS             COMMENT  \\\n",
      "1839       <class 'str'>       <class 'str'>   \n",
      "0     <class 'NoneType'>  <class 'NoneType'>   \n",
      "\n",
      "                                           CREATION_DATE          ORIGINATOR  \\\n",
      "1839  <class 'pandas._libs.tslibs.timestamps.Timestamp'>       <class 'str'>   \n",
      "0          <class 'pandas._libs.tslibs.nattype.NaTType'>  <class 'NoneType'>   \n",
      "\n",
      "             OBJECT_NAME           OBJECT_ID         CENTER_NAME  \\\n",
      "1839       <class 'str'>       <class 'str'>       <class 'str'>   \n",
      "0     <class 'NoneType'>  <class 'NoneType'>  <class 'NoneType'>   \n",
      "\n",
      "               REF_FRAME         TIME_SYSTEM MEAN_ELEMENT_THEORY  \\\n",
      "1839       <class 'str'>       <class 'str'>       <class 'str'>   \n",
      "0     <class 'NoneType'>  <class 'NoneType'>  <class 'NoneType'>   \n",
      "\n",
      "                                                   EPOCH      MEAN_MOTION  \\\n",
      "1839  <class 'pandas._libs.tslibs.timestamps.Timestamp'>  <class 'float'>   \n",
      "0          <class 'pandas._libs.tslibs.nattype.NaTType'>  <class 'float'>   \n",
      "\n",
      "         ECCENTRICITY      INCLINATION   RA_OF_ASC_NODE ARG_OF_PERICENTER  \\\n",
      "1839  <class 'float'>  <class 'float'>  <class 'float'>   <class 'float'>   \n",
      "0     <class 'float'>  <class 'float'>  <class 'float'>   <class 'float'>   \n",
      "\n",
      "         MEAN_ANOMALY EPHEMERIS_TYPE CLASSIFICATION_TYPE   NORAD_CAT_ID  \\\n",
      "1839  <class 'float'>  <class 'int'>       <class 'str'>  <class 'int'>   \n",
      "0     <class 'float'>  <class 'int'>  <class 'NoneType'>  <class 'int'>   \n",
      "\n",
      "     ELEMENT_SET_NO   REV_AT_EPOCH            BSTAR  MEAN_MOTION_DOT  \\\n",
      "1839  <class 'int'>  <class 'int'>  <class 'float'>  <class 'float'>   \n",
      "0     <class 'int'>  <class 'int'>  <class 'float'>  <class 'float'>   \n",
      "\n",
      "     MEAN_MOTION_DDOT   SEMIMAJOR_AXIS           PERIOD         APOAPSIS  \\\n",
      "1839  <class 'float'>  <class 'float'>  <class 'float'>  <class 'float'>   \n",
      "0     <class 'float'>  <class 'float'>  <class 'float'>  <class 'float'>   \n",
      "\n",
      "            PERIAPSIS         OBJECT_TYPE            RCS_SIZE  \\\n",
      "1839  <class 'float'>       <class 'str'>       <class 'str'>   \n",
      "0     <class 'float'>  <class 'NoneType'>  <class 'NoneType'>   \n",
      "\n",
      "            COUNTRY_CODE                                         LAUNCH_DATE  \\\n",
      "1839       <class 'str'>  <class 'pandas._libs.tslibs.timestamps.Timestamp'>   \n",
      "0     <class 'NoneType'>       <class 'pandas._libs.tslibs.nattype.NaTType'>   \n",
      "\n",
      "                    SITE                                     DECAY_DATE  \\\n",
      "1839       <class 'str'>  <class 'pandas._libs.tslibs.nattype.NaTType'>   \n",
      "0     <class 'NoneType'>  <class 'pandas._libs.tslibs.nattype.NaTType'>   \n",
      "\n",
      "               FILE          GP_ID           TLE_LINE0           TLE_LINE1  \\\n",
      "1839  <class 'int'>  <class 'int'>       <class 'str'>       <class 'str'>   \n",
      "0     <class 'int'>  <class 'int'>  <class 'NoneType'>  <class 'NoneType'>   \n",
      "\n",
      "               TLE_LINE2  \n",
      "1839       <class 'str'>  \n",
      "0     <class 'NoneType'>  \n"
     ]
    }
   ],
   "source": [
    "print(df.tail(2).applymap(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 4.35 s, sys: 166 ms, total: 4.52 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 重複データ\n",
    "dup = df.duplicated()\n",
    "print(dup.sum())\n",
    "#print(df[dup].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 38.5 ms, sys: 11.9 ms, total: 50.4 ms\n",
      "Wall time: 48.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 重複データ(GP_IDのみで判定) ← ひとまずこちらで十分\n",
    "dup2 = df.duplicated(subset = ['GP_ID'])\n",
    "print(dup2.sum())\n",
    "#print(df[dup].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "CPU times: user 1.57 s, sys: 125 ms, total: 1.69 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.drop_duplicates(subset = ['GP_ID'], ignore_index = True, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695286796\n",
      "CPU times: user 4.83 s, sys: 1.23 s, total: 6.06 s\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# json で保存 (行指向 records)\n",
    "# date_format を指定しないと、datetime64はシリアル値(64bit整数)として記録される\n",
    "# date_unit で時刻の精度を指定する\n",
    "df.to_json(file_json, orient = 'records', date_format='iso', date_unit='us')\n",
    "print(os.path.getsize(file_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569596326\n",
      "CPU times: user 5.18 s, sys: 1.12 s, total: 6.3 s\n",
      "Wall time: 6.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# json で保存 (列指向 columns)\n",
    "# date_format を指定しないと、datetime64はシリアル値(64bit整数)として記録される\n",
    "# date_unit で時刻の精度を指定する\n",
    "df.to_json(file_json2, orient = 'columns', date_format='iso', date_unit='us')\n",
    "print(os.path.getsize(file_json2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291863412\n",
      "CPU times: user 3.91 s, sys: 522 ms, total: 4.43 s\n",
      "Wall time: 4.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pickle で保存 (無圧縮)\n",
    "df.to_pickle(file_pickle)\n",
    "print(os.path.getsize(file_pickle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80091362\n",
      "CPU times: user 28 s, sys: 381 ms, total: 28.4 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pickle で保存 (gzip圧縮)\n",
    "df.to_pickle(file_pickle2)\n",
    "print(os.path.getsize(file_pickle2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114114066\n",
      "CPU times: user 3.55 s, sys: 442 ms, total: 3.99 s\n",
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parquet で保存 (default: snappy圧縮)\n",
    "df.to_parquet(file_parquet)\n",
    "print(os.path.getsize(file_parquet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89789995\n",
      "CPU times: user 3.59 s, sys: 355 ms, total: 3.95 s\n",
      "Wall time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parquet で保存 (zstd圧縮)\n",
    "df.to_parquet(file_parquet2, compression='zstd')\n",
    "print(os.path.getsize(file_parquet2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852055616\n",
      "CPU times: user 23.6 s, sys: 4.67 s, total: 28.2 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HDFで保存 (pandas.DataFrame.to_hdf を使用)\n",
    "# あとで検索に使えるよう、主要なcolumnにindexをつけておく\n",
    "# format = 'fixed' とすると、レコード数が多いときにエラーが発生する\n",
    "# object型のcolumnにintが含まれているとエラーが発生する\n",
    "df.to_hdf(file_hdf, 'test', mode = 'w', format = 'table', data_columns = columns_index)\n",
    "print(os.path.getsize(file_hdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708069520\n",
      "CPU times: user 23.8 s, sys: 6.83 s, total: 30.7 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HDFで保存 (pandas.HDFStore を使用) → to_hdf と同じモノが生成される\n",
    "# あとで検索に使えるよう、主要なcolumnにindexをつけておく\n",
    "# object型のcolumnにintが含まれているとエラーが発生する\n",
    "store = pd.HDFStore(file_hdf2)\n",
    "store.append('test', df, data_columns = columns_index)\n",
    "store.close()\n",
    "print(os.path.getsize(file_hdf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358428672\n",
      "CPU times: user 15.3 s, sys: 1.54 s, total: 16.8 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SQLite3で保存\n",
    "# 型は、real, integer, text, timestamp に集約される\n",
    "# indexのつけ方については要検討\n",
    "with sqlite3.connect(file_sqlite) as conn:\n",
    "    #c = conn.cursor()\n",
    "    df.to_sql('elset', conn, if_exists='replace', index=None)\n",
    "    conn.execute('CREATE UNIQUE INDEX index_elset_gp_id ON elset (GP_ID)')\n",
    "    conn.execute('CREATE INDEX index_elset_epoch ON elset (EPOCH)')\n",
    "    conn.execute('CREATE INDEX index_elset_norad_cat_id ON elset (NORAD_CAT_ID)')\n",
    "    conn.commit()\n",
    "print(os.path.getsize(file_sqlite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存したデータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n",
      "CPU times: user 17.7 s, sys: 2.91 s, total: 20.7 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# JSONを読み込む (行指向 records)\n",
    "# orient はつけなくてもほとんどの場合自動判別してくれる\n",
    "df_tmp = pd.read_json(file_json, convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'records')\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n",
      "CPU times: user 26.6 s, sys: 1.59 s, total: 28.2 s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# JSONを読み込む (列指向 columns)\n",
    "# orient はつけなくてもほとんどの場合自動判別してくれる\n",
    "df_tmp = pd.read_json(file_json2, convert_dates = convert_dates, dtype = dtype, precise_float = True, orient = 'columns')\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n",
      "CPU times: user 1.4 s, sys: 139 ms, total: 1.54 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pickleを読み込む (無圧縮)\n",
    "df_tmp = pd.read_pickle(file_pickle)\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n",
      "CPU times: user 2.48 s, sys: 85 ms, total: 2.56 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pickleを読み込む (gzip圧縮)\n",
    "df_tmp = pd.read_pickle(file_pickle2)\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n",
      "CPU times: user 2.37 s, sys: 1.01 s, total: 3.38 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parquetを読み込む (default: snappy圧縮)\n",
    "df_tmp = pd.read_parquet(file_parquet)\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n",
      "CPU times: user 2.74 s, sys: 920 ms, total: 3.66 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parquetを読み込む (zstd圧縮)\n",
    "df_tmp = pd.read_parquet(file_parquet2)\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [nan nan NaT nan nan nan nan nan nan nan NaT nan nan nan nan nan nan 0\n",
      "  nan 0 0 0 nan nan nan nan nan nan nan nan nan nan NaT nan NaT 0\n",
      "  4294967295 nan nan nan]]\n",
      "CPU times: user 9.18 s, sys: 1.57 s, total: 10.8 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HDFを読み込む\n",
    "# 文字列型のcolumnの欠損値がnanになっていることに注意\n",
    "df_tmp = pd.read_hdf(file_hdf, 'test')\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249966\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [nan nan NaT nan nan nan nan nan nan nan NaT nan nan nan nan nan nan 0\n",
      "  nan 0 0 0 nan nan nan nan nan nan nan nan nan nan NaT nan NaT 0\n",
      "  4294967295 nan nan nan]]\n",
      "CPU times: user 18.7 s, sys: 2.95 s, total: 21.6 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HDFを読み込む  (pandas.HDFStore を使用)\n",
    "# 文字列型のcolumnの欠損値がnanになっていることに注意\n",
    "store = pd.HDFStore(file_hdf2)\n",
    "df_tmp = store.get('test')\n",
    "store.close()\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "[['2.0' 'GENERATED VIA SPACE-TRACK.ORG API'\n",
      "  Timestamp('2004-08-16 23:12:35') '18 SPCS' 'DELTA 1 DEB' '1977-065GB'\n",
      "  'EARTH' 'TEME' 'UTC' 'SGP4' Timestamp('1980-12-31 15:41:36.007871')\n",
      "  12.00906572 0.0852058 30.9733 123.512 61.6999 306.6869 0 'U' 19638 999\n",
      "  13637 0.014414 3.472e-05 0.0 8054.946 119.909 2363.139 990.482 'DEBRIS'\n",
      "  'SMALL' 'US' Timestamp('1977-07-14 00:00:00') 'AFETR' NaT 34278\n",
      "  11691699 '0 DELTA 1 DEB'\n",
      "  '1 19638U 77065 GB 80366.65388898  .00003472 +00000-0 +14414-1 0  9991'\n",
      "  '2 19638 030.9733 123.5120 0852058 061.6999 306.6869 12.00906572136376']\n",
      " [None None NaT None None None None None None None NaT nan nan nan nan\n",
      "  nan nan 0 None 0 0 0 nan nan nan nan nan nan nan None None None NaT\n",
      "  None NaT 0 4294967295 None None None]]\n",
      "CPU times: user 13.2 s, sys: 1.24 s, total: 14.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SQLite3から読み込む\n",
    "# 型は、real => float64, integer => int64, text => object(str), timestamp => datetime64[ns] となる\n",
    "with sqlite3.connect(file_sqlite) as conn:\n",
    "    df_tmp = pd.read_sql_query(\"SELECT * FROM elset\", conn, parse_dates = convert_dates)\n",
    "print(len(df_tmp))\n",
    "print(df_tmp.tail(2).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一部のデータのみを読んでみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "CPU times: user 506 ms, sys: 187 ms, total: 694 ms\n",
      "Wall time: 630 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>PERIAPSIS</th>\n",
       "      <th>NORAD_CAT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 23:49:31.538495</td>\n",
       "      <td>556.253</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 09:22:09.017759</td>\n",
       "      <td>555.130</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 23:33:02.931552</td>\n",
       "      <td>512.009</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       EPOCH  PERIAPSIS  NORAD_CAT_ID\n",
       "0 1980-01-01 23:49:31.538495    556.253            11\n",
       "1 1980-01-01 09:22:09.017759    555.130            12\n",
       "2 1980-01-01 23:33:02.931552    512.009            20"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# parquetを読み込む (default: snappy圧縮)\n",
    "df_tmp = pd.read_parquet(file_parquet, columns = ['EPOCH', 'PERIAPSIS', 'NORAD_CAT_ID'])\n",
    "print(len(df_tmp))\n",
    "df_tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "CPU times: user 89.4 ms, sys: 56 ms, total: 145 ms\n",
      "Wall time: 66.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>PERIAPSIS</th>\n",
       "      <th>NORAD_CAT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 23:49:31.538495</td>\n",
       "      <td>556.253</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 09:22:09.017759</td>\n",
       "      <td>555.130</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 23:33:02.931552</td>\n",
       "      <td>512.009</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       EPOCH  PERIAPSIS  NORAD_CAT_ID\n",
       "0 1980-01-01 23:49:31.538495    556.253            11\n",
       "1 1980-01-01 09:22:09.017759    555.130            12\n",
       "2 1980-01-01 23:33:02.931552    512.009            20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# parquetを読み込む (zstd圧縮)\n",
    "# 圧縮されているにも関わらず速い。素晴らしい\n",
    "df_tmp = pd.read_parquet(file_parquet2,  columns = ['EPOCH', 'PERIAPSIS', 'NORAD_CAT_ID'])\n",
    "print(len(df_tmp))\n",
    "df_tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624983\n",
      "CPU times: user 9.04 s, sys: 1.52 s, total: 10.6 s\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>PERIAPSIS</th>\n",
       "      <th>NORAD_CAT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 23:49:31.538495</td>\n",
       "      <td>556.253</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 09:22:09.017759</td>\n",
       "      <td>555.130</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 23:33:02.931552</td>\n",
       "      <td>512.009</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       EPOCH  PERIAPSIS  NORAD_CAT_ID\n",
       "0 1980-01-01 23:49:31.538495    556.253            11\n",
       "1 1980-01-01 09:22:09.017759    555.130            12\n",
       "2 1980-01-01 23:33:02.931552    512.009            20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# HDFから一部の列のみを読む\n",
    "# 全体を読むのと同じだけの時間がかかる\n",
    "df_tmp = pd.read_hdf(file_hdf, 'test', columns = ['EPOCH', 'PERIAPSIS', 'NORAD_CAT_ID'])\n",
    "print(len(df_tmp))\n",
    "df_tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "CPU times: user 177 ms, sys: 8.05 ms, total: 185 ms\n",
      "Wall time: 181 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>PERIAPSIS</th>\n",
       "      <th>NORAD_CAT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1980-01-10 07:22:27.352991</td>\n",
       "      <td>1000.781</td>\n",
       "      <td>5691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>1980-01-10 14:23:13.991136</td>\n",
       "      <td>778.811</td>\n",
       "      <td>5693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>1980-01-10 04:11:43.504511</td>\n",
       "      <td>998.643</td>\n",
       "      <td>5694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           EPOCH  PERIAPSIS  NORAD_CAT_ID\n",
       "10000 1980-01-10 07:22:27.352991   1000.781          5691\n",
       "10001 1980-01-10 14:23:13.991136    778.811          5693\n",
       "10002 1980-01-10 04:11:43.504511    998.643          5694"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# HDFから一部の行のみを読む\n",
    "df_tmp = pd.read_hdf(file_hdf, 'test', start = 10000, stop = 19999, columns = ['EPOCH', 'PERIAPSIS', 'NORAD_CAT_ID'])\n",
    "print(len(df_tmp))\n",
    "df_tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6855\n",
      "CPU times: user 261 ms, sys: 168 ms, total: 429 ms\n",
      "Wall time: 424 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>PERIAPSIS</th>\n",
       "      <th>NORAD_CAT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>1980-01-01 01:40:17.353055</td>\n",
       "      <td>178.360</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1980-01-01 12:05:40.756416</td>\n",
       "      <td>178.448</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1980-01-01 12:08:52.446912</td>\n",
       "      <td>168.130</td>\n",
       "      <td>5407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1980-01-01 00:55:45.002783</td>\n",
       "      <td>196.483</td>\n",
       "      <td>12908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>1980-01-01 00:55:49.652831</td>\n",
       "      <td>195.572</td>\n",
       "      <td>12908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          EPOCH  PERIAPSIS  NORAD_CAT_ID\n",
       "604  1980-01-01 01:40:17.353055    178.360          4760\n",
       "605  1980-01-01 12:05:40.756416    178.448          4760\n",
       "746  1980-01-01 12:08:52.446912    168.130          5407\n",
       "1506 1980-01-01 00:55:45.002783    196.483         12908\n",
       "1507 1980-01-01 00:55:49.652831    195.572         12908"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# HDFから条件にマッチした行のみを読む\n",
    "# indexがついている列のみ条件を指定するのに利用できる (to_hdf の data_columns オプション)\n",
    "df_tmp = pd.read_hdf(file_hdf, 'test', where = 'PERIAPSIS<200', columns = ['EPOCH', 'PERIAPSIS', 'NORAD_CAT_ID'])\n",
    "print(len(df_tmp))\n",
    "df_tmp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/_i_table/APOAPSIS/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/APOAPSIS/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/APOAPSIS/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/APOAPSIS/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/APOAPSIS/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/APOAPSIS/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/APOAPSIS/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/APOAPSIS/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/APOAPSIS/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/APOAPSIS/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/ARG_OF_PERICENTER/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/ARG_OF_PERICENTER/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/ARG_OF_PERICENTER/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/BSTAR/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/BSTAR/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/BSTAR/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/BSTAR/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/BSTAR/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/BSTAR/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/BSTAR/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/BSTAR/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/BSTAR/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/BSTAR/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/CREATION_DATE/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/CREATION_DATE/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<i8\">\n",
      "test/_i_table/CREATION_DATE/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/CREATION_DATE/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/CREATION_DATE/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/CREATION_DATE/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<i8\">\n",
      "test/_i_table/CREATION_DATE/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<i8\">\n",
      "test/_i_table/CREATION_DATE/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<i8\">\n",
      "test/_i_table/CREATION_DATE/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<i8\">\n",
      "test/_i_table/CREATION_DATE/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/ECCENTRICITY/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/ECCENTRICITY/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/ECCENTRICITY/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/ECCENTRICITY/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/ECCENTRICITY/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/ECCENTRICITY/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/ECCENTRICITY/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/ECCENTRICITY/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/ECCENTRICITY/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/ECCENTRICITY/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/EPOCH/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/EPOCH/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<i8\">\n",
      "test/_i_table/EPOCH/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/EPOCH/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/EPOCH/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/EPOCH/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<i8\">\n",
      "test/_i_table/EPOCH/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<i8\">\n",
      "test/_i_table/EPOCH/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<i8\">\n",
      "test/_i_table/EPOCH/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<i8\">\n",
      "test/_i_table/EPOCH/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/GP_ID/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/GP_ID/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<u4\">\n",
      "test/_i_table/GP_ID/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/GP_ID/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/GP_ID/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/GP_ID/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<u4\">\n",
      "test/_i_table/GP_ID/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<u4\">\n",
      "test/_i_table/GP_ID/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/GP_ID/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<u4\">\n",
      "test/_i_table/GP_ID/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/INCLINATION/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/INCLINATION/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/INCLINATION/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/INCLINATION/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/INCLINATION/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/INCLINATION/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/INCLINATION/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/INCLINATION/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/INCLINATION/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/INCLINATION/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/MEAN_ANOMALY/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/MEAN_ANOMALY/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/MEAN_ANOMALY/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/MEAN_MOTION/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/MEAN_MOTION/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/MEAN_MOTION/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/NORAD_CAT_ID/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<u4\">\n",
      "test/_i_table/NORAD_CAT_ID/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/OBJECT_ID/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"|S10\">\n",
      "test/_i_table/OBJECT_ID/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"|S10\">\n",
      "test/_i_table/OBJECT_ID/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/OBJECT_ID/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/OBJECT_ID/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"|S10\">\n",
      "test/_i_table/OBJECT_ID/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"|S10\">\n",
      "test/_i_table/OBJECT_ID/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"|S10\">\n",
      "test/_i_table/OBJECT_ID/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"|S10\">\n",
      "test/_i_table/OBJECT_ID/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"|S10\">\n",
      "test/_i_table/OBJECT_ID/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"|S10\">\n",
      "test/_i_table/PERIAPSIS/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/PERIAPSIS/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/PERIAPSIS/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/PERIAPSIS/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/PERIAPSIS/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/PERIAPSIS/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/PERIAPSIS/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/PERIAPSIS/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/PERIAPSIS/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/PERIAPSIS/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/PERIOD/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/PERIOD/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/PERIOD/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/PERIOD/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/PERIOD/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/PERIOD/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/PERIOD/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/PERIOD/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/PERIOD/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/PERIOD/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/RA_OF_ASC_NODE/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/RA_OF_ASC_NODE/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/RA_OF_ASC_NODE/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/REV_AT_EPOCH/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<u4\">\n",
      "test/_i_table/REV_AT_EPOCH/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<u4\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<f8\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<f8\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<f8\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<f8\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<f8\">\n",
      "test/_i_table/SEMIMAJOR_AXIS/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<f8\">\n",
      "test/_i_table/index/abounds \t <HDF5 dataset \"abounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/index/bounds \t <HDF5 dataset \"bounds\": shape (2, 215), type \"<i8\">\n",
      "test/_i_table/index/indices \t <HDF5 dataset \"indices\": shape (2, 221184), type \"<u4\">\n",
      "test/_i_table/index/indicesLR \t <HDF5 dataset \"indicesLR\": shape (221184,), type \"<u4\">\n",
      "test/_i_table/index/mbounds \t <HDF5 dataset \"mbounds\": shape (432,), type \"<i8\">\n",
      "test/_i_table/index/mranges \t <HDF5 dataset \"mranges\": shape (2,), type \"<i8\">\n",
      "test/_i_table/index/ranges \t <HDF5 dataset \"ranges\": shape (2, 2), type \"<i8\">\n",
      "test/_i_table/index/sorted \t <HDF5 dataset \"sorted\": shape (2, 221184), type \"<i8\">\n",
      "test/_i_table/index/sortedLR \t <HDF5 dataset \"sortedLR\": shape (221401,), type \"<i8\">\n",
      "test/_i_table/index/zbounds \t <HDF5 dataset \"zbounds\": shape (432,), type \"<i8\">\n",
      "test/table \t <HDF5 dataset \"table\": shape (624983,), type \"|V1281\">\n",
      "CPU times: user 53.4 ms, sys: 17.4 ms, total: 70.7 ms\n",
      "Wall time: 57.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pandas.DataFrame.to_hdf で保存したHDFの構造\n",
    "def hdfprint(name, obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(name, '\\t', obj)\n",
    "\n",
    "with h5py.File(file_hdf, 'r') as f:\n",
    "    f.visititems(hdfprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "624983\n",
      "CPU times: user 866 ms, sys: 375 ms, total: 1.24 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 単純に読むだけなら速い\n",
    "with h5py.File(file_hdf, 'r') as f:\n",
    "    data = f['test/table'][()]\n",
    "    print(type(data))\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.void'>\n",
      "24\n",
      "(0, [b'2.0', b'EARTH', b'U', b'GENERATED VIA SPACE-TRACK.ORG API', b'US', b'SGP4', b'VANGUARD 2', b'PAYLOAD', b'18 SPCS', b'MEDIUM', b'TEME', b'AFETR', b'UTC', b'0 VANGUARD 2', b'1 00011U 59001  A 80001.99272614  .00001182 +00000-0 +68517-3 0  9998', b'2 00011 032.8934 225.7732 1604011 342.2735 012.7600 11.56641400878142'], [-9223372036854775808,  -343094400000000000], [999], [0], [34111], [0.000e+00, 1.182e-05], 1092613538000000000, 315618571538495000, b'1959-001A', 11.566414, 0.1604011, 32.8934, 225.7732, 342.2735, 12.76, 11, 87814, 0.00068517, 8259.167, 124.498, 3205.812, 556.253, 11069028)\n",
      "CPU times: user 3.94 ms, sys: 3 ms, total: 6.94 ms\n",
      "Wall time: 6.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1行目を読んでみる\n",
    "# 型ごとにまとめられたリストになっているのでそのままでは使えない\n",
    "with h5py.File(file_hdf, 'r') as f:\n",
    "    data = f['test/table'][0]\n",
    "    print(type(data))\n",
    "    print(len(data))\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 3.09 ms, sys: 803 µs, total: 3.89 ms\n",
      "Wall time: 3.08 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>PERIAPSIS</th>\n",
       "      <th>NORAD_CAT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EPOCH, PERIAPSIS, NORAD_CAT_ID]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SQLite3から読み込む\n",
    "# 型は、real => float64, integer => int64, text => object(str), timestamp => datetime64[ns] となる\n",
    "with sqlite3.connect(file_sqlite) as conn:\n",
    "    df_tmp = pd.read_sql_query('''SELECT EPOCH, PERIAPSIS, NORAD_CAT_ID \n",
    "        FROM elset WHERE NORAD_CAT_ID BETWEEN 80000 AND 89000''', conn, parse_dates = convert_dates)\n",
    "print(len(df_tmp))\n",
    "df_tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6855\n",
      "CPU times: user 132 ms, sys: 137 ms, total: 269 ms\n",
      "Wall time: 267 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>PERIAPSIS</th>\n",
       "      <th>NORAD_CAT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 01:40:17.353055</td>\n",
       "      <td>178.360</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 12:05:40.756416</td>\n",
       "      <td>178.448</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 12:08:52.446912</td>\n",
       "      <td>168.130</td>\n",
       "      <td>5407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       EPOCH  PERIAPSIS  NORAD_CAT_ID\n",
       "0 1980-01-01 01:40:17.353055    178.360          4760\n",
       "1 1980-01-01 12:05:40.756416    178.448          4760\n",
       "2 1980-01-01 12:08:52.446912    168.130          5407"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SQLite3から読み込む (indexがついていないと遅い例)\n",
    "# 型は、real => float64, integer => int64, text => object(str), timestamp => datetime64[ns] となる\n",
    "with sqlite3.connect(file_sqlite) as conn:\n",
    "    df_tmp = pd.read_sql_query('''SELECT EPOCH, PERIAPSIS, NORAD_CAT_ID \n",
    "                               FROM elset WHERE PERIAPSIS < 200''', conn, parse_dates = convert_dates)\n",
    "print(len(df_tmp))\n",
    "df_tmp.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
